{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: You must have LaTeX installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full search block-based ME (Motion Estimation)\n",
    "The predicted frame is divided into blocks and each one is characterized by a motion vector using exhaustive search. This guarantees reaching the global optimal (the best motion field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt update\n",
    "    !apt install imagemagick\n",
    "    !apt install cm-super\n",
    "    !apt install dvipng\n",
    "    !apt install bc\n",
    "    !apt install texlive-latex-extra\n",
    "    !apt install texlive-fonts-recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    from skimage import io\n",
    "#except:\n",
    "#    !pip install scikit-image\n",
    "#    from skimage import io\n",
    "try:\n",
    "    from scipy import ndimage\n",
    "except:\n",
    "    !pip install scipy\n",
    "    from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\" #for \\text command\n",
    "   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from color_transforms import YCoCg\n",
    "except:\n",
    "    !pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "    from color_transforms import YCoCg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image\n",
    "except:\n",
    "    !pip install \"image_IO @ git+https://github.com/vicente-gonzalez-ruiz/image_IO\"\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import full_search\n",
    "    import display\n",
    "    import prediction\n",
    "except:\n",
    "    !pip install \"motion_estimation @ git+https://github.com/vicente-gonzalez-ruiz/motion_estimation\"\n",
    "    from motion_estimation import full_search\n",
    "    from motion_estimation import display\n",
    "    from motion_estimation import prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_synthesis\" ]; then\n",
    "    cd $HOME/repos/image_synthesis\n",
    "    echo \"$HOME/repos/image_synthesis ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_synthesis.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a moving-circles sequence\n",
    "There are two circles, moving horizontally in oposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "frames=5\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/right -x 32 -y 16 -w 64 -h 32 -f $frames -d 10\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/left -x 32 -y 16 -w 64 -h 32 -f $frames -d 10 -a 0 -b -1\n",
    "set -x\n",
    "i=0\n",
    "while [ $i -le $((frames-1)) ]\n",
    "do\n",
    "    ii=$(printf \"%03d\" $i)\n",
    "    convert -append /tmp/right${ii}.png /tmp/left${ii}.png /tmp/${ii}.png\n",
    "    i=$(( $i + 1 ))\n",
    "done\n",
    "set -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/001.png\").astype(np.int16)[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home = os.environ[\"HOME\"]\n",
    "#R = YUV.from_RGB(image_3.read(home + \"/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(home + \"/MRVC/sequences/moving_circles/\", 1).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference $R$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gray_image.show(P, \"predicted $P$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top circle moves to the right and the bottom circle moves to the left. Therefore, if we want to generate the predicted frame (bottom) from the reference one (top), all the top MVs (Motion Vectors) related to the circle should be (x=1, y=0), and all the bottom MVs (-1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_side = 32\n",
    "max_abs_motion = 2\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(P.shape[0]//block_side):\n",
    "    for x in range(P.shape[1]//block_side):\n",
    "        print(MVs[y, x], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate the MVs\n",
    "The predictor expects a dense motion field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted $P$\")\n",
    "gray_image.show(hat_P, \"prediction $\\hat{P}$\")\n",
    "gray_image.show(P - hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/002.png\").astype(np.int16)[...,0]\n",
    "#R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 2).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 4\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "gray_image.show(P - hat_P, \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/004.png\").astype(np.int16)[...,0]\n",
    "#R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 4).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 8\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "gray_image.show(P-hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with a real image\n",
    "A tile of Stockholm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=\"https://hpca.ual.es/~vruiz/videos/\"\n",
    "sequence=\"stockholm_1280x768x50x420x578.avi\"\n",
    "output_prefix=\"/tmp/original_\"\n",
    "number_of_frames=16\n",
    "first_frame=2\n",
    "~/repos/image_synthesis/extract_frames.sh -u $URL -s $sequence -o $output_prefix -n $number_of_frames -f $first_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... but first without using ME\n",
    "Notice that we work only with a tile of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_Y = slice(100,356)\n",
    "slice_X = slice(100,612)\n",
    "sequence = \"/tmp/original_\"\n",
    "R = RGB_image.read(sequence + \"002.png\")[slice_Y, slice_X]\n",
    "P = RGB_image.read(sequence + \"003.png\")[slice_Y, slice_X]\n",
    "RGB_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "entropy = information.entropy(P.flatten())\n",
    "RGB_image.show(P, \"predicted ${\\mathbf P}$\" + f\" entropy={entropy:1.2f} bits/component\")\n",
    "predicted_entropy = entropy\n",
    "P_R = np.clip(P.astype(np.int16) - R + 128, 0, 255)\n",
    "entropy = information.entropy(P_R.flatten())\n",
    "RGB_image.show(P_R.astype(np.uint8), \"(No ME) $({\\mathbf P} - {\\mathbf R})$\" + f\" entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and now using BBME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 32\n",
    "max_abs_motion = 8\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = information.entropy(MVs.flatten())\n",
    "motion_entropy = entropy\n",
    "display.show_vectors(MVs[::1, ::1], title=\"${\\mathbf V}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\" +  f\", {MVs.shape[0]}x{MVs.shape[1]} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[0]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[1]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "zoom_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "zoom_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(zoom_MVs[::10, ::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, zoom_MVs)\n",
    "RGB_image.show(P, \"predicted ${\\mathbf P}$\" + f\" entropy={predicted_entropy:1.2f} bits/component\")\n",
    "RGB_image.show(hat_P, \"$\\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\")\n",
    "P_hat_P = P - hat_P + 128\n",
    "entropy = information.entropy(P_hat_P.flatten())\n",
    "residue_entropy = entropy\n",
    "RGB_image.show(P_hat_P.astype(np.uint8), \"${\\mathbf P} - \\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entropy of the predicted frame:                 \", f\"{predicted_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the residue frame:                   \", f\"{residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy reduction in the texture:               \", f\"{predicted_entropy - residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the components of the motion vectors:\", f\"{motion_entropy:1.3f}\", \"bits/component\")\n",
    "texture_length = residue_entropy * P.size\n",
    "motion_length = motion_entropy * MVs.size\n",
    "total_length = texture_length + motion_length\n",
    "total_entropy = total_length / P.size\n",
    "print(\"Entropy the texture + motion vectors:           \", f\"{total_entropy:1.3f}\", \"bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (visually) the ME on other sequences (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
