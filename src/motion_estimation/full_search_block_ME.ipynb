{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full search block-based ME (Motion Estimation)\n",
    "The predicted frame is divided into blocks and each one is characterized by a motion vector using exhaustive search. This guarantees reaching the global optimal (the best motion field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    from skimage import io\n",
    "#except:\n",
    "#    !pip install scikit-image\n",
    "#    from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from color_transforms import YCoCg\n",
    "except:\n",
    "    !pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "    from color_transforms import YCoCg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image\n",
    "except:\n",
    "    !pip install \"image_IO @ git+https://github.com/vicente-gonzalez-ruiz/image_IO\"\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import full_search\n",
    "    import display\n",
    "    import prediction\n",
    "except:\n",
    "    !pip install \"motion_estimation @ git+https://github.com/vicente-gonzalez-ruiz/motion_estimation\"\n",
    "    from motion_estimation import full_search\n",
    "    from motion_estimation import display\n",
    "    from motion_estimation import prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_synthesis\" ]; then\n",
    "    cd $HOME/repos/image_synthesis\n",
    "    echo \"$HOME/repos/image_synthesis ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_synthesis.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !apt update\n",
    "    !apt install imagemagick\n",
    "    !apt install cm-super\n",
    "    !apt install dvipng\n",
    "    !apt install bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a moving-circles sequence\n",
    "There are two circles, moving horizontally in oposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "frames=5\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/right -x 32 -y 16 -w 64 -h 32 -f $frames -d 10\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/left -x 32 -y 16 -w 64 -h 32 -f $frames -d 10 -a 0 -b -1\n",
    "set -x\n",
    "i=0\n",
    "while [ $i -le $((frames-1)) ]\n",
    "do\n",
    "    ii=$(printf \"%03d\" $i)\n",
    "    convert -append /tmp/right${ii}.png /tmp/left${ii}.png /tmp/${ii}.png\n",
    "    i=$(( $i + 1 ))\n",
    "done\n",
    "set -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/001.png\").astype(np.int16)[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home = os.environ[\"HOME\"]\n",
    "#R = YUV.from_RGB(image_3.read(home + \"/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(home + \"/MRVC/sequences/moving_circles/\", 1).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference $R$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gray_image.show(P, \"predicted $P$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top circle moves to the right and the bottom circle moves to the left. Therefore, if we want to generate the predicted frame (bottom) from the reference one (top), all the top MVs (Motion Vectors) related to the circle should be (x=1, y=0), and all the bottom MVs (-1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __full_search_block_based_ME(P, R, block_side=16, max_abs_motion=8):\n",
    "    \n",
    "    def local_search(by, bx):\n",
    "        errors_by_search_area = np.empty((2*max_abs_motion + 1, 2*max_abs_motion + 1))\n",
    "        for ry in range(-max_abs_motion, max_abs_motion + 1):\n",
    "            for rx in range(-max_abs_motion, max_abs_motion + 1):\n",
    "                R_block = extended_R[by*block_side + ry + max_abs_motion:\n",
    "                                    (by + 1)*block_side + ry + max_abs_motion,\n",
    "                                    bx*block_side + rx + max_abs_motion:\n",
    "                                    (bx + 1)*block_side + rx + max_abs_motion]\n",
    "                #show_frame(R_block, f\"R ({by} {bx} {ry} {rx} {by*block_side + ry + max_abs_motion}:{(by + 1)*block_side + ry + max_abs_motion}, {bx*block_side + rx + max_abs_motion}:{(bx + 1)*block_side + rx + max_abs_motion})\")\n",
    "                P_block = P[by*block_side : (by + 1)*block_side, bx*block_side : (bx + 1)*block_side]\n",
    "                #show_frame(P_block, f\"P ({by*block_side}:{(by + 1)*block_side},{bx*block_side}:{(bx + 1)*block_side})\")\n",
    "                #errors_in_search_area = np.abs(R_block - P_block)\n",
    "                #error_by_block = np.sum(errors_in_search_area)\n",
    "                error = R_block.astype(np.float32) - P_block\n",
    "                errors_in_search_area = error*error\n",
    "                error_by_block = np.average(errors_in_search_area)\n",
    "                #show_frame(errors_in_search_area, f\"by={by} bx={bx} ry={ry} rx={rx} error={error_by_block}\")\n",
    "                errors_by_search_area[ry + max_abs_motion, rx + max_abs_motion] = error_by_block\n",
    "                #show_frame(errors_by_search_area, \"errors\")\n",
    "        mv_index = np.argmin(errors_by_search_area)\n",
    "        if errors_by_search_area[max_abs_motion, max_abs_motion] == errors_by_search_area[0, 0]:\n",
    "            MV_y, MV_x = 0, 0\n",
    "        else:\n",
    "            MV_y = mv_index // (2*max_abs_motion + 1) - max_abs_motion\n",
    "            MV_x = mv_index  % (2*max_abs_motion + 1) - max_abs_motion\n",
    "        #print(\"index=\", mv_index, \"y=\", MV_y, \"x=\", MV_x)\n",
    "        #print(errors_by_search_area.astype(np.int))\n",
    "        return MV_y, MV_x\n",
    "\n",
    "    assert max_abs_motion > 0\n",
    "    extended_R = cv.copyMakeBorder(R, max_abs_motion, max_abs_motion, max_abs_motion, max_abs_motion, cv.BORDER_REPLICATE) \n",
    "    extended_R[max_abs_motion : R.shape[0] + max_abs_motion,\n",
    "               max_abs_motion : R.shape[1] + max_abs_motion] = R\n",
    "    #show_frame(extended_R, \"extended R\")\n",
    "    blocks_in_y = P.shape[0]//block_side\n",
    "    blocks_in_x = P.shape[1]//block_side\n",
    "    MVs = np.zeros((blocks_in_y, blocks_in_x, 2), dtype=np.int8)\n",
    "    #print(blocks_in_y, blocks_in_x)\n",
    "    for by in range(blocks_in_y):\n",
    "        for bx in range(blocks_in_x):\n",
    "            MV_y, MV_x = local_search(by, bx)\n",
    "            MVs[by, bx] = (MV_x, MV_y)\n",
    "    return MVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_side = 32\n",
    "max_abs_motion = 2\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(P.shape[0]//block_side):\n",
    "    for x in range(P.shape[1]//block_side):\n",
    "        print(MVs[y, x], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate the MVs\n",
    "The predictor expects a dense motion field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted $P$\")\n",
    "gray_image.show(hat_P, \"prediction $\\hat{P}$\")\n",
    "gray_image.show(P - hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/002.png\").astype(np.int16)[...,0]\n",
    "#R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 2).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 4\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "gray_image.show(P - hat_P, \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\").astype(np.int16)[...,0]\n",
    "P = RGB_image.read(\"/tmp/004.png\").astype(np.int16)[...,0]\n",
    "#R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "#P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 4).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 8\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "display.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, _MVs)\n",
    "gray_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "gray_image.show(P-hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with a real image\n",
    "A tile of Stockholm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=\"https://hpca.ual.es/~vruiz/videos/\"\n",
    "sequence=\"stockholm_1280x768x50x420x578.avi\"\n",
    "output_prefix=\"/tmp/original_\"\n",
    "number_of_frames=16\n",
    "first_frame=2\n",
    "~/repos/image_synthesis/extract_frames.sh -u $URL -s $sequence -o $output_prefix -n $number_of_frames -f $first_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... but first without using ME\n",
    "Notice that we work only with a tile of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_Y = slice(100,356)\n",
    "slice_X = slice(100,612)\n",
    "sequence = \"/tmp/original_\"\n",
    "R = RGB_image.read(sequence + \"002.png\")[slice_Y, slice_X]\n",
    "P = RGB_image.read(sequence + \"003.png\")[slice_Y, slice_X]\n",
    "RGB_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "entropy = information.entropy(P.flatten())\n",
    "RGB_image.show(P, \"predicted ${\\mathbf P}$\" + f\" entropy={entropy:1.2f} bits/component\")\n",
    "predicted_entropy = entropy\n",
    "P_R = np.clip(P.astype(np.int16) - R + 128, 0, 255)\n",
    "entropy = information.entropy(P_R.flatten())\n",
    "RGB_image.show(P_R.astype(np.uint8), \"(No ME) $({\\mathbf P} - {\\mathbf R})$\" + f\" entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and now using BBME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 32\n",
    "max_abs_motion = 8\n",
    "MVs = full_search.block_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = information.entropy(MVs.flatten())\n",
    "motion_entropy = entropy\n",
    "display.show_vectors(MVs[::1, ::1], title=\"${\\mathbf V}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\" +  f\", {MVs.shape[0]}x{MVs.shape[1]} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[0]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[1]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "zoom_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "zoom_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "zoom_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(zoom_MVs[::10, ::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, zoom_MVs)\n",
    "RGB_image.show(P, \"predicted ${\\mathbf P}$\" + f\" entropy={predicted_entropy:1.2f} bits/component\")\n",
    "RGB_image.show(hat_P, \"$\\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\")\n",
    "P_hat_P = P - hat_P + 128\n",
    "entropy = information.entropy(P_hat_P.flatten())\n",
    "residue_entropy = entropy\n",
    "RGB_image.show(P_hat_P.astype(np.uint8), \"${\\mathbf P} - \\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entropy of the predicted frame:                 \", f\"{predicted_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the residue frame:                   \", f\"{residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy reduction in the texture:               \", f\"{predicted_entropy - residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the components of the motion vectors:\", f\"{motion_entropy:1.3f}\", \"bits/component\")\n",
    "texture_length = residue_entropy * P.size\n",
    "motion_length = motion_entropy * MVs.size\n",
    "total_length = texture_length + motion_length\n",
    "total_entropy = total_length / P.size\n",
    "print(\"Entropy the texture + motion vectors:           \", f\"{total_entropy:1.3f}\", \"bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (visually) the ME on other sequences (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
