{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: You must have LaTeX installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farnebäck's motion estimation\n",
    "\n",
    "Farnebäck estimates the dense (1x1) optical flow (with subpixel accuracy) assuming that the frames are similar in texture and the motion is smooth. In general, this last requirement generates motion fields more visually coherent and smoother that in the case of block-based ME algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt update\n",
    "    !apt install imagemagick\n",
    "    !apt install cm-super\n",
    "    !apt install dvipng\n",
    "    !apt install bc\n",
    "    !apt install texlive-latex-extra\n",
    "    !apt install texlive-fonts-recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\" #for \\text command\n",
    "   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from color_transforms import YCoCg as YUV\n",
    "except:\n",
    "    !pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "    from color_transforms import YCoCg as YUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image\n",
    "except:\n",
    "    !pip install \"image_IO @ git+https://github.com/vicente-gonzalez-ruiz/image_IO\"\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import optical_flow as motion\n",
    "    import display\n",
    "    import prediction\n",
    "except:\n",
    "    !pip install \"motion_estimation @ git+https://github.com/vicente-gonzalez-ruiz/motion_estimation\"\n",
    "    from motion_estimation import optical_flow as motion\n",
    "    from motion_estimation import display\n",
    "    from motion_estimation import prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_synthesis\" ]; then\n",
    "    cd $HOME/repos/image_synthesis\n",
    "    echo \"$HOME/repos/image_synthesis ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_synthesis.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farnebäck basis transform\n",
    "Farnebäck's algorithm does not compare pixels, but transform coefficients resulting of convolving the following basis fuctions. This decreases the computational requirements the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = np.sin(tau)**2+np.cos(tau)**2+0.005\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'1')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant motion in the X direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$y$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp, cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant motion in the Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$x$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contant motion in both directions (at the same time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau*phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$xy$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant acceleration in the Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau*tau\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$x^2$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant acceleration in the X direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = phi*phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$y^2$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a moving-circles sequence\n",
    "There are two circles, moving horizontally in oposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "frames=5\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/right -x 32 -y 16 -w 64 -h 32 -f $frames -d 10\n",
    "~/repos/image_synthesis/moving_circle.sh -o /tmp/left -x 32 -y 16 -w 64 -h 32 -f $frames -d 10 -a 0 -b -1\n",
    "set -x\n",
    "i=0\n",
    "while [ $i -le $((frames-1)) ]\n",
    "do\n",
    "    ii=$(printf \"%03d\" $i)\n",
    "    convert -append /tmp/right${ii}.png /tmp/left${ii}.png /tmp/${ii}.png\n",
    "    i=$(( $i + 1 ))\n",
    "done\n",
    "set -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\")\n",
    "P = RGB_image.read(\"/tmp/001.png\")\n",
    "R_Y = YUV.from_RGB(R.astype(np.int16))[...,0]\n",
    "P_Y = YUV.from_RGB(P.astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R_Y, \"Reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray_image.show(P_Y, \"Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top circle moves to the right and the bottom circle moves to the left. Therefore, if we want to generate the predicted frame (bottom) from the reference one (top), all the top MVs (Motion Vectors) related to the circle should be (x=1, y=0), and all the bottom MVs (-1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_MVs = np.zeros((P_Y.shape[0], P_Y.shape[1], 2), dtype=np.float32)\n",
    "MVs = motion.Farneback_ME(predicted=P_Y, reference=R_Y, initial_MVs=initial_MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(reference=R, MVs=MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.dtype, MVs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RGB_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "RGB_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "RGB_image.show((P - hat_P + 128).astype(np.uint8), \"prediction error ($P-\\hat{P}$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\")\n",
    "P = RGB_image.read(\"/tmp/002.png\")\n",
    "R_Y = YUV.from_RGB(R.astype(np.int16))[...,0]\n",
    "P_Y = YUV.from_RGB(P.astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R_Y, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P_Y, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_MVs = np.zeros((P_Y.shape[0], P_Y.shape[1], 2), dtype=np.float32)\n",
    "MVs = motion.Farneback_ME(predicted=P_Y, reference=R_Y, initial_MVs=initial_MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, MVs)\n",
    "RGB_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "RGB_image.show((P - hat_P + 128).astype(np.uint8), \"prediction error ($P-\\hat{P}$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB_image.read(\"/tmp/000.png\")\n",
    "P = RGB_image.read(\"/tmp/004.png\")\n",
    "R_Y = YUV.from_RGB(R.astype(np.int16))[...,0]\n",
    "P_Y = YUV.from_RGB(P.astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(R, \"reference ${\\mathbf R}$\")\n",
    "gray_image.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_MVs = np.zeros((P_Y.shape[0], P_Y.shape[1], 2), dtype=np.float32)\n",
    "MVs = motion.Farneback_ME(predicted=P_Y, reference=R_Y, initial_MVs=initial_MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, MVs)\n",
    "RGB_image.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "RGB_image.show((P - hat_P + 128).astype(np.uint8), \"prediction error ($P-\\hat{P}$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Farnebäck's ME does not always minimizes the L$_2$ distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile of Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=\"https://hpca.ual.es/~vruiz/videos/\"\n",
    "sequence=\"stockholm_1280x768x50x420x578.avi\"\n",
    "output_prefix=\"/tmp/original_\"\n",
    "number_of_frames=16\n",
    "first_frame=2\n",
    "~/repos/image_synthesis/extract_frames.sh -u $URL -s $sequence -o $output_prefix -n $number_of_frames -f $first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_Y = slice(100,356)\n",
    "slice_X = slice(100,612)\n",
    "sequence = \"/tmp/original_\"\n",
    "R = RGB_image.read(sequence + \"003.png\")[slice_Y, slice_X]\n",
    "P = RGB_image.read(sequence + \"004.png\")[slice_Y, slice_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Y = YUV.from_RGB(R.astype(np.int16))[...,0]\n",
    "P_Y = YUV.from_RGB(P.astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_MVs = np.zeros((P_Y.shape[0], P_Y.shape[1], 2), dtype=np.float32)\n",
    "MVs = motion.Farneback_ME(predicted=P_Y, reference=R_Y, initial_MVs=initial_MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = information.entropy(MVs.flatten())\n",
    "display.show_vectors(MVs[::10, ::10], title=\"${\\mathbf V}$ (Farnebäck) \" + f\"entropy={entropy:1.2f} bits/component\" + f\", {MVs.shape[0]}x{MVs.shape[1]} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = prediction.make(R, MVs)\n",
    "RGB_image.show(hat_P, \"$\\hat{\\mathbf P}$ (Farnebäck)\")\n",
    "P_hat_P = P - hat_P + 128\n",
    "entropy = information.entropy(P_hat_P.flatten())\n",
    "RGB_image.show(P_hat_P.astype(np.uint8), \"${\\mathbf P}$ - $\\hat{\\mathbf P}$ (Farnebäck)\" + f\" entropy={entropy:1.2f} bits/pixel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Farneback provides subpixel accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another implementation\n",
    "https://github.com/ericPrince/optical-flow/blob/master/optical_flow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from functools import partial\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "__all__ = [\"__version__\", \"poly_exp\", \"flow_iterative\"]\n",
    "\n",
    "\n",
    "__version__ = \"1.0.0\"\n",
    "\n",
    "\n",
    "def poly_exp(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 2D signal, as described by Farneback\n",
    "    Uses separable normalized correlation\n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    If f[i, j] and c[i, j] are the signal value and certainty of pixel (i, j) then\n",
    "    A[i, j] is a 2x2 array representing the quadratic term of the polynomial, B[i, j]\n",
    "    is a 2-element array representing the linear term, and C[i, j] is a scalar\n",
    "    representing the constant term.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    # Calculate applicability kernel (1D because it is separable)\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))  # a: applicability kernel [n]\n",
    "\n",
    "    # b: calculate b from the paper. Calculate separately for X and Y dimensions\n",
    "    # [n, 6]\n",
    "    bx = np.stack(\n",
    "        [np.ones(a.shape), x, np.ones(a.shape), x**2, np.ones(a.shape), x], axis=-1\n",
    "    )\n",
    "    by = np.stack(\n",
    "        [\n",
    "            np.ones(a.shape),\n",
    "            np.ones(a.shape),\n",
    "            x,\n",
    "            np.ones(a.shape),\n",
    "            x**2,\n",
    "            x,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [bx.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [bx.shape[-1]])\n",
    "\n",
    "    # Apply separable cross-correlations\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, bx)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, bx)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, by)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, by)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                G[..., i, j], abb[..., i, j], axis=1, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            v[..., i], ab[..., i], axis=1, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [2, 2])\n",
    "    A[..., 0, 0] = r[..., 3]\n",
    "    A[..., 0, 1] = r[..., 5] / 2\n",
    "    A[..., 1, 0] = A[..., 0, 1]\n",
    "    A[..., 1, 1] = r[..., 4]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [2])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    B[..., 1] = r[..., 2]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    return A, B, C\n",
    "\n",
    "\n",
    "def flow_iterative(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First image\n",
    "    f2\n",
    "        Second image\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first image\n",
    "    c2\n",
    "        Certainty of second image\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i, j] is the (y, x) displacement for pixel (i, j)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the images\n",
    "    A1, B1, C1 = poly_exp(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images\n",
    "    x = np.stack(\n",
    "        np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])),\n",
    "        axis=-1,\n",
    "    ).astype(np.int32)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [2])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(np.int32)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2)\n",
    "        ATA = S_T @ A_T @ A @ S\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # \n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0, 1))\n",
    "            h_avg = np.mean(ATb, axis=(0, 1))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "          \n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d\n",
    "\n",
    "def OF(f1, f2): # f1 and f2 double's\n",
    "    # certainties for images - certainty is decreased for pixels near the edge\n",
    "    # of the image, as recommended by Farneback\n",
    "\n",
    "    # c1 = np.ones_like(f1)\n",
    "    # c2 = np.ones_like(f2)\n",
    "\n",
    "    c1 = np.minimum(\n",
    "        1, 1 / 5 * np.minimum(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1]))\n",
    "    )\n",
    "    c1 = np.minimum(\n",
    "        c1,\n",
    "        1\n",
    "        / 5\n",
    "        * np.minimum(\n",
    "            f1.shape[0] - 1 - np.arange(f1.shape[0])[:, None],\n",
    "            f1.shape[1] - 1 - np.arange(f1.shape[1]),\n",
    "        ),\n",
    "    )\n",
    "    c2 = c1\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # calculate optical flow with this algorithm\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    n_pyr = 4\n",
    "\n",
    "    # # version using perspective warp regularization\n",
    "    # # to clean edges\n",
    "    # opts = dict(\n",
    "    #     sigma=4.0,\n",
    "    #     sigma_flow=4.0,\n",
    "    #     num_iter=3,\n",
    "    #     model='eight_param',\n",
    "    #     mu=None,\n",
    "    # )\n",
    "\n",
    "    # version using no regularization model\n",
    "    opts = dict(\n",
    "        sigma=4.0,\n",
    "        sigma_flow=4.0,\n",
    "        num_iter=3,\n",
    "        model=\"constant\",\n",
    "        mu=0,\n",
    "    )\n",
    "\n",
    "    # optical flow field\n",
    "    d = None\n",
    "\n",
    "    # calculate optical flow using pyramids\n",
    "    # note: reversed(...) because we start with the smallest pyramid\n",
    "    for pyr1, pyr2, c1_, c2_ in reversed(\n",
    "        list(\n",
    "            zip(\n",
    "                *list(\n",
    "                    map(\n",
    "                        partial(skimage.transform.pyramid_gaussian, max_layer=n_pyr),\n",
    "                        [f1, f2, c1, c2],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ):\n",
    "        if d is not None:\n",
    "            # TODO: account for shapes not quite matching\n",
    "            #d = skimage.transform.pyramid_expand(d, multichannel=True)\n",
    "            d = skimage.transform.pyramid_expand(d, channel_axis=2)\n",
    "            d = d[: pyr1.shape[0], : pyr2.shape[1]]\n",
    "\n",
    "        d = flow_iterative(pyr1, pyr2, c1=c1_, c2=c2_, d=d, **opts)\n",
    "\n",
    "    xw = d + np.moveaxis(np.indices(f1.shape), 0, -1)\n",
    "    return xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MVs = OF(P_Y, R_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_w = skimage.transform.warp(R_Y, np.moveaxis(MVs, -1, 0), cval=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"gray\"\n",
    "plt.imshow(R_Y, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(f2_w, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_w.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(f2_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max((f2_w*255).astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min((f2_w*255).astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show((f2_w*255).astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
