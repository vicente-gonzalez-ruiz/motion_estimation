{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing FarnebÃ¤ck's optical flow estimator 1n 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_OpenCV = False\n",
    "use_OpenCV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt update\n",
    "    !apt install imagemagick\n",
    "    !apt install cm-super\n",
    "    !apt install dvipng\n",
    "    !apt install bc\n",
    "    !apt install texlive-latex-extra\n",
    "    !apt install texlive-fonts-recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/PEs/farneback-python/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in /shared/PEs/farneback-python/lib/python3.10/site-packages (24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    !pip install scipy\n",
    "    import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import skimage\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    import pylab\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\" #for \\text command\n",
    "   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from color_transforms import YCoCg as YUV\n",
    "except:\n",
    "    !pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "    from color_transforms import YCoCg as YUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image\n",
    "except:\n",
    "    !pip install \"image_IO @ git+https://github.com/vicente-gonzalez-ruiz/image_IO\"\n",
    "    from image_IO import image_1 as gray_image\n",
    "    from image_IO import image_3 as RGB_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    from information_theory import information\n",
    "    #from information_theory import distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    import motion_estimation\n",
    "    #import optical_flow as motion\n",
    "    #from motion_estimation import farneback\n",
    "    #from motion_estimation import display\n",
    "    #from motion_estimation import project\n",
    "except:\n",
    "    !pip install \"motion_estimation @ git+https://github.com/vicente-gonzalez-ruiz/motion_estimation\"\n",
    "    #from motion_estimation import farneback\n",
    "    import motion_estimation\n",
    "    #import display\n",
    "    #import prediction\n",
    "    #from motion_estimation import optical_flow as motion\n",
    "    #from motion_estimation import farneback as motion_estimator\n",
    "    #from motion_estimation import display\n",
    "    #from motion_estimation import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_OpenCV:\n",
    "    from motion_estimation._2D.farneback_OpenCV import Estimator_in_CPU as Estimator\n",
    "else:\n",
    "    from motion_estimation._1D.farneback_python import Farneback as Estimator\n",
    "from motion_estimation._1D.project import project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile of Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=\"https://hpca.ual.es/~vruiz/videos/\"\n",
    "sequence=\"stockholm_1280x768x50x420x578.avi\"\n",
    "output_prefix=\"/tmp/original_\"\n",
    "number_of_frames=16\n",
    "first_frame=2\n",
    "~/repos/image_synthesis/extract_frames.sh -u $URL -s $sequence -o $output_prefix -n $number_of_frames -f $first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"/tmp/original_\"\n",
    "img = RGB_image.read(sequence + \"003.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_Y = YUV.from_RGB(img.astype(np.int16))[..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_OpenCV:\n",
    "    w = 25\n",
    "    reference_slice=img_Y[500:500 + w]\n",
    "    target_slice=img_Y[501:501 + w]\n",
    "else:\n",
    "    R = img_Y[500]\n",
    "    P = np.roll(R, 10)\n",
    "    plt.plot(P)\n",
    "    plt.plot(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_OpenCV:\n",
    "    estimator = Estimator(win_side=w, pyr_levels=3, verbosity=logging.WARNING)\n",
    "    print(reference_slice.shape)\n",
    "    initial_flow = np.zeros(shape=(reference_slice.shape[0], reference_slice.shape[1], 2), dtype=np.float32)\n",
    "    flow = estimator.pyramid_get_flow(target=target_slice, reference=reference_slice, flow=initial_flow)\n",
    "else:\n",
    "    estimator = Estimator(sigma_poly=4.0, sigma_flow=4.0, pyr_levels=3, verbosity=logging.WARNING)\n",
    "    initial_flow = np.zeros_like(R, dtype=np.float32)\n",
    "    flow = estimator.pyramid_get_flow(target=P, reference=R, flow=initial_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion_estimation._2D.helpers import show_vectors\n",
    "show_vectors(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion_estimation._2D.project import project\n",
    "compensated_slice = project(reference_slice, flow)\n",
    "compensated_line = compensated_slice[(w + 1) >> 1, :]\n",
    "#compensated_line = np.roll(compensated_line, -w//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E0 = target_slice[(w + 1) >> 1, :] - reference_slice[(w + 1) >> 1, :]\n",
    "E1 = target_slice[(w + 1) >> 1, :] - compensated_line\n",
    "plt.plot(E0, label=\"without OF\")\n",
    "plt.plot(E1, label=\"with OF\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_OpenCV:\n",
    "    estimator = Estimator(win_side=w, pyr_levels=3, verbosity=logging.WARNING)\n",
    "    E0 = np.zeros_like(img_Y, dtype=np.int16)\n",
    "    E1 = np.zeros_like(img_Y, dtype=np.int16)\n",
    "    P0 = np.zeros_like(img_Y, dtype=np.uint8)\n",
    "    P1 = np.zeros_like(img_Y, dtype=np.uint8)\n",
    "    for i in range(img_Y.shape[0] - w):\n",
    "        print(i, end=' ')\n",
    "        R = img_Y[i:i + w]\n",
    "        T = img_Y[i + 1: i + 1 + w]\n",
    "        initial_flow = np.zeros(shape=(R.shape[0], R.shape[1], 2), dtype=np.float32)\n",
    "        flow = estimator.pyramid_get_flow(target=T, reference=R, flow=initial_flow)\n",
    "        compensated_slice = project(R, flow)\n",
    "        compensated_line = compensated_slice[(w + 1) >> 1, :]\n",
    "        E0[i] = T[(w + 1) >> 1, :] - R[(w + 1) >> 1, :]\n",
    "        E1[i] = T[(w + 1) >> 1, :] - compensated_line\n",
    "        P0[i] = R[(w + 1) >> 1, :]\n",
    "        P1[i] = compensated_line\n",
    "else:\n",
    "    estimator = Estimator(sigma_poly=4.0, sigma_flow=4.0, pyr_levels=2, verbosity=logging.WARNING)\n",
    "    from numpy.linalg import LinAlgError\n",
    "    E0 = np.empty_like(img_Y, dtype=np.int16)\n",
    "    E1 = np.empty_like(img_Y, dtype=np.int16)\n",
    "    for i in range(img_Y.shape[0] - 1):\n",
    "        print(i, end=' ')\n",
    "        R = img_Y[i]\n",
    "        P = img_Y[i+1]\n",
    "        try:\n",
    "            initial_flow = np.zeros_like(R, dtype=np.float32)\n",
    "            MVs = estimator.pyramid_get_flow(target=P, reference=R, flow=initial_flow)\n",
    "        except LinAlgError as e:\n",
    "            print(f\"Caught LinAlgError: {e}\")\n",
    "            MVs = np.zeros_like(R)\n",
    "        hat_P = project(R, np.squeeze(MVs))\n",
    "        E0[i] = P - R\n",
    "        E1[i] = P - hat_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E0.astype(np.int8), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E1.astype(np.int8), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(P0, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(P1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_Y, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E0.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E1.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_slice[(win_side + 1) >> 1, :])\n",
    "plt.plot(compensated_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_slice[(win_side + 1) >> 1, :])\n",
    "plt.plot(compensated_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reference_slice, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow[(win_side+1)//2][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flow[(win_side+1)//2][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = project(R, np.squeeze(flow))\n",
    "E1 = (P - hat_P).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(E1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = img_Y[500]\n",
    "P = img_Y[501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P)\n",
    "plt.plot(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(sigma_poly=4.0, sigma_flow=4.0, pyr_levels=2, verbosity=logging.WARNING)\n",
    "initial_flow = np.zeros_like(R, dtype=np.float32)\n",
    "flow = estimator.pyramid_get_flow(target=P, reference=R, flow=initial_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = project(R, np.squeeze(flow))\n",
    "E0 = P - R\n",
    "E1 = (P - hat_P).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(E0)\n",
    "plt.plot(E1)\n",
    "plt.plot(E0, label=\"without OF\")\n",
    "plt.plot(E1, label=\"with OF\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Using all the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator = Estimator(sigma_poly=4.0, sigma_flow=4.0, pyr_levels=2, verbosity=logging.WARNING)\n",
    "from numpy.linalg import LinAlgError\n",
    "E0 = np.empty_like(img_Y, dtype=np.int16)\n",
    "E1 = np.empty_like(img_Y, dtype=np.int16)\n",
    "for i in range(img_Y.shape[0] - 1):\n",
    "    print(i, end=' ')\n",
    "    R = img_Y[i]\n",
    "    P = img_Y[i+1]\n",
    "    try:\n",
    "        initial_flow = np.zeros_like(R, dtype=np.float32)\n",
    "        MVs = estimator.pyramid_get_flow(target=P, reference=R, flow=initial_flow)\n",
    "    except LinAlgError as e:\n",
    "        print(f\"Caught LinAlgError: {e}\")\n",
    "        MVs = np.zeros_like(R)\n",
    "    hat_P = project(R, np.squeeze(MVs))\n",
    "    E0[i] = P - R\n",
    "    E1[i] = P - hat_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E0, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E0.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E1.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(MVs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = project(R_Y, np.squeeze(MVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E0 = P_Y - R_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1 = (P_Y - hat_P).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(R_Y)\n",
    "plt.plot(hat_P)\n",
    "plt.plot(E0, label=\"without OF\")\n",
    "plt.plot(E1, label=\"with OF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.entropy(E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E0, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(E1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.ones_like(R_Y)\n",
    "MVs = estimator.get_flow(np.roll(R_Y,10), R_Y, c, c, mu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.swapaxes(R, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.swapaxes(R, 0, 1)\n",
    "P = np.swapaxes(P, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Y = YUV.from_RGB(R.astype(np.int16))[..., 0]\n",
    "P_Y = YUV.from_RGB(P.astype(np.int16))[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_Y, P_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_Y.shape, P_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_MVs = np.zeros((P_Y.shape[0], P_Y.shape[1], 2), dtype=np.float32)\n",
    "#MVs = motion.Farneback_ME(predicted=P_Y, reference=R_Y, initial_MVs=initial_MVs)\n",
    "MVs = estimator.get_flow(target=P_Y, reference=R_Y, prev_flow=initial_MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(MVs), np.min(MVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray_image.show(np.stack([R_Y, R_Y, R_Y, P_Y, P_Y, P_Y]), size=(30,10))\n",
    "gray_image.show(np.stack([R_Y, P_Y], axis=0).reshape(6, 256), size=(30,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_estimation.helpers.show_vectors(MVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = RGB_image.read(sequence + \"015.png\")[100:356, 100:456]\n",
    "RGB_image.show(img,\"\")\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export OPENCV_LOG_LEVEL=DEBUG\n",
    "\n",
    "def filter_AAABBB(Y_img):\n",
    "    # Iterate over rows\n",
    "    total_flow_through_rows = []\n",
    "    flow = np.zeros((3, Y_img.shape[1], 2), dtype=np.float32)\n",
    "    for y in range(Y_img.shape[0]-1):\n",
    "        prev = np.stack([Y_img[y], Y_img[y], Y_img[y]])\n",
    "        #prev = np.stack([Y_img[y], Y_img[y+1], Y_img[y]])\n",
    "        next = np.stack([Y_img[y+1], Y_img[y+1], Y_img[y+1]])\n",
    "        #print(prev)\n",
    "        if y==10:\n",
    "            print(prev.shape, next.shape, flow.shape)\n",
    "            print(np.max(prev), np.max(next))\n",
    "        flow = motion.Farneback_ME(predicted=next, reference=prev, initial_MVs=flow, wside=3)\n",
    "        total_flow_through_rows.append(flow[1])\n",
    "    # Iterate over columns\n",
    "    total_flow_through_cols = []\n",
    "    flow = np.zeros((3, Y_img.shape[0], 2), dtype=np.float32)\n",
    "    for x in range(Y_img.shape[1]-1):\n",
    "        prev = np.stack([Y_img[:, x], Y_img[:, x], Y_img[:, x]])\n",
    "        next = np.stack([Y_img[:, x+1], Y_img[:, x+1], Y_img[:, x+1]])\n",
    "        flow = motion.Farneback_ME(predicted=next, reference=prev, initial_MVs=flow, wside=3)\n",
    "        total_flow_through_cols.append(flow[1])\n",
    "    return np.stack(total_flow_through_rows), np.stack(total_flow_through_cols)\n",
    "\n",
    "N = 5\n",
    "\n",
    "def filter_AAABBB(Y_img):\n",
    "    print(np.average(Y_img))\n",
    "    extended_img = np.zeros(shape=(Y_img.shape[0]+N, Y_img.shape[1]+N), dtype=Y_img.dtype)\n",
    "    extended_img[N//2:Y_img.shape[0]+N//2, N//2:Y_img.shape[1]+N//2] = Y_img[:, :]\n",
    "    # Iterate over rows\n",
    "    total_flow_rows_pass = []\n",
    "    prev_flow = np.zeros((N, Y_img.shape[1], 2), dtype=np.float32)\n",
    "    N_rows = Y_img.shape[0]\n",
    "    c = 0\n",
    "    for y in range(N_rows):\n",
    "        #prev = np.stack([Y_img[y], Y_img[(y+1)%N_rows], Y_img[(y+2)%N_rows]])\n",
    "        #next = np.stack([Y_img[(y+3)%N_rows], Y_img[(y+4)%N_rows], Y_img[(y+5)%N_rows]])\n",
    "        #prev = np.stack([Y_img[y], Y_img[y], Y_img[y]])\n",
    "        #next = np.stack([Y_img[(y+1)%N_rows], Y_img[(y+1)%N_rows], Y_img[(y+1)%N_rows]])\n",
    "        prev = extended_img[y:y+N]\n",
    "        #next = np.roll(prev, 1, axis=1)\n",
    "        next = extended_img[y+1:y+1+N]\n",
    "        assert prev.shape==next.shape, f\"{c} {prev.shape} {next.shape}\"\n",
    "        #print(prev)\n",
    "        #print(next)\n",
    "        #print(prev)\n",
    "        #if y==10:\n",
    "        #    print(prev.shape, next.shape, flow[1].shape)\n",
    "        #    print(np.max(prev), np.max(next))\n",
    "        #    print(np.max(Y_img[y]), np.max(Y_img))\n",
    "        #    print(prev, next)\n",
    "        #flow = motion.Farneback_ME(predicted=next, reference=prev, initial_MVs=prev_flow, wside=N)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev=prev, next=next, flow=None,\n",
    "                                            pyr_scale=0.5, levels=0, winsize=N,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "                                            flags=0)\n",
    "        #prev_flow = flow.copy()\n",
    "        #flow = np.random.rand(flow.size).reshape(flow.shape).astype(np.float32)\n",
    "        print(c, np.max(np.abs(flow[N>>1][..., 0])), np.max(np.abs(flow[N>>1][..., 1])))\n",
    "        #print(flow.shape)\n",
    "        #print(np.unravel_index(np.argmax(abs(flow[1])), flow[1].shape), np.max(abs(flow[1])), end=' ')\n",
    "        total_flow_rows_pass.append(flow[N>>1][..., 0])\n",
    "        #print(flow[0], total_flow_rows_pass)\n",
    "        max = 0\n",
    "        for i in total_flow_rows_pass:\n",
    "            _max = np.max(np.abs(i))\n",
    "            if _max > max:\n",
    "                max = _max\n",
    "        #print(\"max=\", max)\n",
    "        c += 1\n",
    "    #print(len(total_flow_rows_pass))\n",
    "    #print(total_flow_rows_pass)\n",
    "    #for i in total_flow_rows_pass:\n",
    "    #    if np.max(np.abs(i)) != 0.0:\n",
    "    #        print(\"!\", end='')\n",
    "    #total_flow_rows_pass = np.array(total_flow_rows_pass).reshape((Y_img.shape[0], Y_img.shape[1]))\n",
    "    total_flow_rows_pass = np.stack(total_flow_rows_pass)\n",
    "    print(\"max=\", np.max(np.abs(total_flow_rows_pass)))\n",
    "    # Iterate over columns\n",
    "    total_flow_cols_pass = []\n",
    "    flow = np.zeros((N, Y_img.shape[0], 2), dtype=np.float32)\n",
    "    N_cols = Y_img.shape[1]\n",
    "    for x in range(N_cols):\n",
    "        prev = np.stack([Y_img[:, x], Y_img[:, x], Y_img[:, x]])\n",
    "        next = np.stack([Y_img[:, (x+1)%N_cols], Y_img[:, (x+1)%N_cols], Y_img[:, (x+1)%N_cols]])\n",
    "        #prev = np.stack([Y_img[:, x], Y_img[:, (x+1)%N_cols], Y_img[:, (x+2)%N_cols]])\n",
    "        #next = np.stack([Y_img[:, (x+3)%N_cols], Y_img[:, (x+4)%N_cols], Y_img[:, (x+4)%N_cols]])\n",
    "        #flow = motion.Farneback_ME(predicted=next, reference=prev, initial_MVs=flow, wside=3)\n",
    "        total_flow_cols_pass.append(flow[N>>1][..., 1])\n",
    "    #total_flow_cols_pass = np.stack(total_flow_cols_pass)\n",
    "    total_flow_cols_pass = np.array(total_flow_cols_pass).reshape(Y_img.shape)\n",
    "    return total_flow_rows_pass, total_flow_cols_pass\n",
    "\n",
    "def get_fields(Y_img):\n",
    "    extended_img = np.zeros(shape=(Y_img.shape[0]+N, Y_img.shape[1]+N), dtype=Y_img.dtype)\n",
    "    extended_img[N//2:Y_img.shape[0]+N//2, N//2:Y_img.shape[1]+N//2] = Y_img[:, :]\n",
    "    # Iterate over rows\n",
    "    total_flow_rows_pass = []\n",
    "    prev_flow = np.zeros((N, Y_img.shape[1], 2), dtype=np.float32)\n",
    "    N_rows = Y_img.shape[0]\n",
    "    c = 0\n",
    "    for y in range(N_rows):\n",
    "        prev = extended_img[y:y+N]\n",
    "        #next = np.roll(prev, 1, axis=1)\n",
    "        next = extended_img[y+1:y+1+N]\n",
    "        #prev_flow = flow.copy()\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev=prev, next=next, flow=None,\n",
    "                                            pyr_scale=0.5, levels=0, winsize=N,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "                                            flags=0)\n",
    "        #flow = np.random.rand(flow.size).reshape(flow.shape).astype(np.float32)\n",
    "        #print(c, np.max(np.abs(flow[N>>1][..., 0])), np.max(np.abs(flow[N>>1][..., 1])))\n",
    "        #print(np.unravel_index(np.argmax(abs(flow[1])), flow[1].shape), np.max(abs(flow[1])), end=' ')\n",
    "        #total_flow_rows_pass.append(flow[N>>1][..., 0])\n",
    "        total_flow_rows_pass.append(flow[(N>>1) + 1, :, 0])\n",
    "        c += 1\n",
    "\n",
    "    #total_flow_rows_pass = np.array(total_flow_rows_pass).reshape((Y_img.shape[0], Y_img.shape[1]))\n",
    "    total_flow_rows_pass = np.stack(total_flow_rows_pass)\n",
    "    # Iterate over columns\n",
    "    total_flow_cols_pass = []\n",
    "    flow = np.zeros((Y_img.shape[0], N, 2), dtype=np.float32)\n",
    "    N_cols = Y_img.shape[1]\n",
    "    for x in range(N_cols):\n",
    "        prev = extended_img[..., x:x+N]\n",
    "        next = extended_img[..., x+1:x+1+N]\n",
    "        #print(prev.shape, next.shape)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev=prev, next=next, flow=None,\n",
    "                                            pyr_scale=0.5, levels=0, winsize=N,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "                                            flags=0)\n",
    "        #print(flow[..., N>>1, 1].shape)\n",
    "        total_flow_cols_pass.append(flow[..., (N>>1) + 1, 1])\n",
    "    total_flow_cols_pass = np.stack(total_flow_cols_pass, axis=1)\n",
    "    #total_flow_cols_pass = np.array(total_flow_cols_pass).reshape(Y_img.shape)\n",
    "    return total_flow_rows_pass, total_flow_cols_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_img = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:105,100:107])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:125,100:125])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:225,100:225])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:625,100:625])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[10:758,10:1270])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:125,100:225])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[100:668,100:1180])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img[40:740,40:1170])\n",
    "#flow_rows, flow_cols = filter_AAABBB(Y_img)\n",
    "flow_rows, flow_cols = get_fields(Y_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "768*1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(flow_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "768*1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(flow_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.imshow(X=flow_rows, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.imshow(X=flow_cols, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(flow_rows*255,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(flow_cols*255,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow(prev, next, l=3, w=5, prev_flow=None):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prev, next=next, flow=prev_flow,\n",
    "                                        pyr_scale=0.5, levels=l, winsize=w,\n",
    "                                        iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "                                        flags=0)\n",
    "    return flow[(N>>1) + 1, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_filtering(img, kernel):\n",
    "    KS = kernel.size\n",
    "    KS2 = KS//2\n",
    "    extended_img = np.zeros(shape=(img.shape[0] + KS, img.shape[1] + KS), dtype=img.dtype)\n",
    "    extended_img[KS2:img.shape[0] + KS2, KS2:img.shape[1] + KS2] = img[:, :]\n",
    "    N_rows = img.shape[0]\n",
    "    tmp_slice = np.zeros(shape=(img.shape[1]))\n",
    "    for y in range(N_rows):\n",
    "        for i in range(KS2 - 1, -1, -1):\n",
    "            prev = extended_img[y:y + w]\n",
    "            next = extended_img[y + 1:y + 1 + w]\n",
    "            flow = get_flow(prev, next, l, w, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Gaussian filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def vertical_gaussian_filtering(img, kernel, mean):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    extended_img = np.full(fill_value=mean, shape=(img.shape[0] + KL, img.shape[1]))\n",
    "    extended_img[KL2:img.shape[0] + KL2, :] = img[:, :]\n",
    "    filtered_img = []\n",
    "    #filtered_img = np.empty_like(img, dtype=np.float32)\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    #horizontal_line = np.empty(N_cols, dtype=np.float32)\n",
    "    #print(horizontal_line.shape)\n",
    "    for y in range(N_rows):\n",
    "        #horizontal_line.fill(0)\n",
    "        horizontal_line = np.zeros(N_cols, dtype=np.float32)\n",
    "        for i in range(KL):\n",
    "            horizontal_line += extended_img[y + i, :] * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "        #filtered_img[y, :] = horizontal_line[:]\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    return filtered_img\n",
    "\n",
    "def horizontal_gaussian_filtering(img, kernel, mean):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    extended_img = np.full(fill_value=mean, shape=(img.shape[0], img.shape[1] + KL))\n",
    "    extended_img[:, KL2:img.shape[1] + KL2] = img[:, :]\n",
    "    #filtered_img = []\n",
    "    filtered_img = np.empty_like(img, dtype=np.float32)\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    vertical_line = np.empty(N_rows, dtype=np.float32)\n",
    "    for x in range(N_cols):\n",
    "        #vertical_line = np.zeros(N_rows, dtype=np.float32)\n",
    "        vertical_line.fill(0)\n",
    "        for i in range(KL):\n",
    "            vertical_line += extended_img[:, x + i] * kernel[i]\n",
    "        #filtered_img.append(vertical_line)\n",
    "        filtered_img[:, x] = vertical_line[:]\n",
    "    #filtered_img = np.stack(filtered_img, axis=1)\n",
    "    return filtered_img\n",
    "\n",
    "def gaussian_filtering(img, kernel):\n",
    "    mean = np.average(img)\n",
    "    t0 = time.perf_counter()\n",
    "    filtered_img_Y = vertical_gaussian_filtering(img, kernel, mean)\n",
    "    t1 = time.perf_counter()\n",
    "    print(t1 - t0)\n",
    "    filtered_img_YX = horizontal_gaussian_filtering(filtered_img_Y, kernel, mean)\n",
    "    t2 = time.perf_counter()\n",
    "    print(t2 - t1)\n",
    "    return filtered_img_YX\n",
    "\n",
    "def gaussian_kernel(sigma):\n",
    "    number_of_coeffs = 3\n",
    "    number_of_zeros = 0\n",
    "    while number_of_zeros < 2 :\n",
    "        delta = np.zeros(number_of_coeffs)\n",
    "        delta[delta.size//2] = 1\n",
    "        coeffs = scipy.ndimage.gaussian_filter1d(delta, sigma=sigma)\n",
    "        number_of_zeros = coeffs.size - np.count_nonzero(coeffs)\n",
    "        number_of_coeffs += 1\n",
    "    return coeffs[1:-1]\n",
    "\n",
    "def color_gaussian_filtering(img, kernel):\n",
    "    filtered_img_R = gaussian_filtering(img[..., 0], kernel)\n",
    "    filtered_img_G = gaussian_filtering(img[..., 1], kernel)\n",
    "    filtered_img_B = gaussian_filtering(img[..., 2], kernel)\n",
    "    return np.stack([filtered_img_R, filtered_img_G, filtered_img_B], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gaussian_kernel(2.0)\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D OF-driven Gaussian filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def horizontal_OF_gaussian_filtering(img, kernel, mean=128, l=3 , w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    extended_img = np.full(fill_value=mean, shape=(img.shape[0], img.shape[1] + KL + 2*w, img.shape[2]))\n",
    "    extended_img[:, KL2 + w:img.shape[1] + KL2 + w] = img[:, :]\n",
    "    filtered_img = []\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    for x in range(N_cols):\n",
    "        vertical_line = np.zeros(N_rows, dtype=np.float32)\n",
    "        for i in range(KL):\n",
    "            reference = extended_img[:, x + i    :x + i     + w] \n",
    "            target    = extended_img[:, x + i + 1:x + i + 1 + w]\n",
    "            flow = get_flow(target, reference, l, w, None)\n",
    "            #OF_compensated_slice = warp_slice(reference, flow)\n",
    "            OF_compensated_slice = warp_slice(target, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[: , (w + 1) >> 1]\n",
    "            vertical_line += OF_compensated_line * kernel[i]\n",
    "\n",
    "        filtered_img.append(vertical_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=1)\n",
    "    return filtered_img\n",
    "\n",
    "def vertical_OF_gaussian_filtering(Y_img, img, kernel, mean, l=3 , w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    extended_Y_img = np.full(fill_value=mean[0], shape=(Y_img.shape[0] + KL + 2*w, Y_img.shape[1]))\n",
    "    extended_Y_img[KL2 + w:Y_img.shape[0] + KL2 + w, :] = Y_img[:, :]\n",
    "    filtered_img = []\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    flow_rows = []\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(N_cols, dtype=np.float32)\n",
    "        for i in range(KL):\n",
    "            #reference = extended_img[y + i    :y + i     + w, :] \n",
    "            #target    = extended_img[y + i + 1:y + i + 1 + w, :]\n",
    "            reference = extended_img[y    :y     + w, :] \n",
    "            target    = extended_img[y + i:y + i + w, :]\n",
    "            #assert reference.shape == target.shape, f\"{reference.shape} {target.shape}\"\n",
    "            flow = get_flow(target, reference, l, w, None)\n",
    "            #flow = get_flow(reference, target, l, w, None)\n",
    "            OF_compensated_slice = warp_slice(reference, flow)\n",
    "            #OF_compensated_slice = warp_slice(target, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "            if i==0: #i==(KL-1):\n",
    "                flow_rows.append(flow[(w + 1)>>1, :, 0])\n",
    "        filtered_img.append(horizontal_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    flow_rows = np.stack(flow_rows)\n",
    "    return filtered_img, flow_rows\n",
    "\n",
    "\n",
    "def OF_gaussian_filtering(Y_img, img, kernel, l=3, w=5):\n",
    "    mean = [np.average(img)[..., 0], np.average(img)[..., 1], np.average(img)[..., 2]]\n",
    "    t0 = time.perf_counter()\n",
    "    filtered_img_y, _ = vertical_OF_gaussian_filtering(Y_img, img, kernel, mean, l , w)\n",
    "    t1 = time.perf_counter()\n",
    "    print(t1 - t0)\n",
    "    filtered_img_yx = horizontal_OF_gaussian_filtering(Y_img, filtered_img_y, kernel, mean, l , w)\n",
    "    #filtered_img_YX = horizontal_OF_gaussian_filtering(img, kernel, mean, l , w)\n",
    "    t2 = time.perf_counter()\n",
    "    print(t2 - t1)\n",
    "    return filtered_img_yx, _\n",
    "\n",
    "def color_OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    Y_img = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    filtered_img,_ = OF_gaussian_filtering(Y_img, img, kernel, l , w)\n",
    "    #filtered_img_G,_ = OF_gaussian_filtering(Y_img, img, kernel, l , w)\n",
    "    #filtered_img_B,_ = OF_gaussian_filtering(Y_img, img, kernel, l , w)\n",
    "    #return np.stack([filtered_img_R, filtered_img_G, filtered_img_B], axis=2), flow_rows\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_slice(reference, flow):\n",
    "    height, width = flow.shape[:2]\n",
    "    map_x = np.tile(np.arange(width), (height, 1))\n",
    "    map_y = np.swapaxes(np.tile(np.arange(height), (width, 1)), 0, 1)\n",
    "    map_xy = (flow + np.dstack((map_x, map_y))).astype('float32')\n",
    "    warped_slice = cv2.remap(reference, map_xy, None,\n",
    "                             interpolation=cv2.INTER_LINEAR,\n",
    "                             borderMode=cv2.BORDER_REPLICATE)\n",
    "    return warped_slice\n",
    "\n",
    "def get_flow(reference, target, l=3, w=5, prev_flow=None):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=target, next=reference, flow=prev_flow,\n",
    "                                            pyr_scale=0.5, levels=l, winsize=w,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "                                            flags=0)\n",
    "    return flow\n",
    "\n",
    "def OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    Y = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    w2 = w//2\n",
    "    extended_Y = cv2.resize(src = Y, dsize = (Y.shape[1] + KL + w, Y.shape[0] + KL + w))\n",
    "    extended_Y[KL2:Y.shape[0] + KL2, KL2:Y.shape[1] + KL2] = Y[...]\n",
    "    \n",
    "    # Filtering along the vertical direction\n",
    "    filtered_img = []\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(shape=(N_cols, img.shape[2]), dtype=np.float32)\n",
    "        reference_slice_Y = extended_Y[y:y + w, :]\n",
    "        for i in range(KL2):\n",
    "            target_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            print(target_slice_Y.shape, reference_slice_Y.shape, w, y, i)\n",
    "            flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            reference_slice = img[y:y + w, :]\n",
    "            OF_compensated_vertical_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_vertical_line = OF_compensated_vertical_slice[(w + 1) >> 1, :, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        horizontal_line += img[y, :, :] * kernel[KL2]\n",
    "        for i in range(KL2 + 1, KL):\n",
    "            target_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            reference_slice = img[y:y + w, :]\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)    \n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    \n",
    "    img = filtered_img\n",
    "    \n",
    "    # Horizontal direction\n",
    "    filtered_img = []\n",
    "    for x in range(N_cols):\n",
    "        vertical_line = np.zeros(shape=(N_rows, img.shape[2]), dtype=np.float32)\n",
    "        reference_slice_Y = Y[:, x:x + w] \n",
    "        for i in range(KL2):\n",
    "            target_slice_Y = Y[:, x + i:x + i + w]\n",
    "            flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            reference = img[:, x:x + w]\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[: , (w + 1) >> 1, :]\n",
    "            vertical_line += OF_compensated_line * kernel[i]\n",
    "        vertical_line += img[:, x, :] * kernel[KL2]\n",
    "        for i in range(KL2 + 1, KL):\n",
    "            target_slice_Y = Y[:, x + i:x + i + w]\n",
    "            flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            reference = img[:, x:x + w]\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[: , (w + 1) >> 1, :]\n",
    "            vertical_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(vertical_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=1)\n",
    "    \n",
    "    return filtered_img\n",
    "\n",
    "def _OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    w2 = w//2\n",
    "    Y = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    #Y_mean = np.average(Y_img)[..., 0]\n",
    "    # Signal extension?\n",
    "    #extended_Y_img = np.full(fill_value=mean[0], shape=(Y_img.shape[0] + KL + 2*w, Y_img.shape[1] + KL + 2*w))\n",
    "    extended_Y = cv2.resize(src = Y, dsize = (Y.shape[1] + KL + w, Y.shape[0] + KL + w))\n",
    "    extended_Y[KL2 + w:Y.shape[0] + KL2 + w2, KL2 + w:Y.shape[1] + KL2 + w2] = Y[...]\n",
    "    #extended_img = np.full(fill_value=mean[0], shape=(img.shape[0] + KL + 2*w, img.shape[1] + KL + 2*w, img.shape[3]))\n",
    "    extended_img = cv2.resize(src = img, dsize = (img.shape[1] + KL + 2*w, img.shape[0] + KL + 2*w))\n",
    "    extended_img[KL2 + w:img.shape[0] + KL2 + w2, KL2 + w:img.shape[1] + KL2 + w2] = img[...]\n",
    "    print(extended_img.shape)\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    \n",
    "    # Vertical\n",
    "    filtered_img = []\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(shape=(N_cols, img.shape[2]), dtype=np.float32)\n",
    "        reference_slice_Y = extended_Y[y + KL2:y + KL2 + w, :]\n",
    "        for i in range(0, KL2):\n",
    "            target_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "        for i in range(KL):\n",
    "            # For i=0, the flow==0, and this case can be out of the loop\n",
    "            target_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            flow = get_flow(target_Y, reference_Y, l, w, None)\n",
    "            #reference = extended_img[y:y + w, :]\n",
    "            reference = extended_img[y:y + w, :]\n",
    "            OF_compensated_slice = warp_slice(reference, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :, :]\n",
    "            print(reference.shape, OF_compensated_slice.shape, OF_compensated_line.shape)\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    \n",
    "    extended_img[KL2 + w:img.shape[0] + KL2 + w, KL2 + w:img.shape[1] + KL2 + w] = filtered_img[...]\n",
    "    \n",
    "    # Horizontal\n",
    "    filtered_img = []\n",
    "    for x in range(N_cols):\n",
    "        vertical_line = np.zeros(N_rows, dtype=np.float32)\n",
    "        for i in range(KL):\n",
    "            reference_Y = extended_Y[:, x    :x +   + w] \n",
    "            target_Y    = extended_Y[:, x + i:x + i + w]\n",
    "            flow = get_flow(target_Y, reference_Y, l, w, None)\n",
    "            reference = extended_img[:, x:x + w]\n",
    "            OF_compensated_slice = warp_slice(reference, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[: , (w + 1) >> 1]\n",
    "            vertical_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(vertical_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=1)\n",
    "    \n",
    "    return filtered_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_OF_gaussian_filtering(img, kernel, l =3, w=5):\n",
    "    '''This method '''\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    Y = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    w2 = w//2\n",
    "    extended_Y = cv2.resize(src = Y, dsize = (Y.shape[1] + KL + w, Y.shape[0] + KL + w))\n",
    "    extended_Y[KL2:Y.shape[0] + KL2, KL2:Y.shape[1] + KL2] = Y[...]\n",
    "    #extended_img = np.full(fill_value=128, shape=(img.shape[0] + KL, img.shape[1], img.shape[2]))\n",
    "    extended_img = cv2.resize(src = img, dsize = (Y.shape[1], Y.shape[0] + KL))\n",
    "    print(extended_img.shape)\n",
    "    extended_img[KL2:img.shape[0] + KL2, :, :] = img[:, :, :]\n",
    "    \n",
    "    filtered_img = []\n",
    "    #filtered_img = np.empty_like(img, dtype=np.float32)\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    #horizontal_line = np.empty(N_cols, dtype=np.float32)\n",
    "    #print(horizontal_line.shape)\n",
    "    for y in range(N_rows):\n",
    "        #horizontal_line.fill(0)\n",
    "        horizontal_line = np.zeros(shape=(N_cols, img.shape[2]), dtype=np.float32)\n",
    "        reference_slice_Y = extended_Y[y:y + w, :]\n",
    "        reference_slice = img[y:y + w, :]\n",
    "        for i in range(KL):\n",
    "            #horizontal_line += extended_img[y + i, :] * kernel[i]\n",
    "            target_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            #print(target_slice_Y.shape, reference_slice_Y.shape, w, y, i)\n",
    "            flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, KL2+w2+1:-KL2-w2-1, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "        #filtered_img[y, :] = horizontal_line[:]\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow(reference, target, l=3, w=5, prev_flow=None):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=target, next=reference, flow=prev_flow,\n",
    "                                            pyr_scale=0.5, levels=l, winsize=w,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=0.5,\n",
    "                                            flags=0)\n",
    "    return flow\n",
    "\n",
    "def vertical_OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    Y = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    w2 = w//2\n",
    "    extended_Y = cv2.resize(src = Y, dsize = (Y.shape[1] + KL + w, Y.shape[0] + KL + w))\n",
    "    extended_Y[KL2:Y.shape[0] + KL2, KL2:Y.shape[1] + KL2] = Y[...]\n",
    "    #extended_img = np.full(fill_value=128, shape=(img.shape[0] + KL, img.shape[1], img.shape[2]))\n",
    "    extended_img = cv2.resize(src = img, dsize = (Y.shape[1], Y.shape[0] + KL))\n",
    "    #print(extended_img.shape)\n",
    "    extended_img[KL2:img.shape[0] + KL2, :, :] = img[:, :, :]\n",
    "    \n",
    "    filtered_img = []\n",
    "    #filtered_img = np.empty_like(img, dtype=np.float32)\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    #horizontal_line = np.empty(N_cols, dtype=np.float32)\n",
    "    #print(horizontal_line.shape)\n",
    "    for y in range(N_rows - KL - w):\n",
    "        #horizontal_line.fill(0)\n",
    "        horizontal_line = np.zeros(shape=(N_cols, img.shape[2]), dtype=np.float32)\n",
    "        #reference_slice_Y = extended_Y[y:y + w, :]\n",
    "        target_slice_Y = Y[y + KL2:y + KL2 + w, :]\n",
    "        target_slice = img[y + KL2:y + KL2 + w, :]\n",
    "        for i in range(KL):\n",
    "            #horizontal_line += extended_img[y + i, :] * kernel[i]\n",
    "            #horizontal_line += img[(y + i) % img.shape[0], :] * kernel[i]\n",
    "            reference_slice_Y = Y[y + i:y + i + w, :]\n",
    "            reference_slice = img[y + i:y + i + w, :]\n",
    "            #print(target_slice_Y.shape, reference_slice_Y.shape, w, y, i)\n",
    "            #flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            flow = get_flow(reference_slice_Y, target_slice_Y, l, w, None)\n",
    "            #flow = get_flow(reference_slice_Y, reference_slice_Y, l, w, None)\n",
    "            #flow = np.zeros((reference_slice_Y.shape[0], reference_slice_Y.shape[1], 2), dtype=np.float32)\n",
    "            #print(flow.shape, reference_slice.shape, reference_slice.dtype)\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            #OF_compensated_slice = warp_slice(target_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :, :]\n",
    "            #OF_compensated_line = OF_compensated_slice[0, :, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "        #filtered_img[y, :] = horizontal_line[:]\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    return filtered_img\n",
    "\n",
    "def _vertical_OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    Y = YUV.from_RGB(img.astype(np.int16))[..., 0]\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    w2 = w//2\n",
    "    extended_Y = cv2.resize(src = Y, dsize = (Y.shape[1] + KL + w, Y.shape[0] + KL + w))\n",
    "    extended_Y[KL2:Y.shape[0] + KL2, KL2:Y.shape[1] + KL2] = Y[...]\n",
    "    extended_img = cv2.resize(src = img, dsize = (Y.shape[1], Y.shape[0] + KL))\n",
    "    extended_img[KL2:img.shape[0] + KL2, :, :] = img[:, :, :]\n",
    "    \n",
    "    filtered_img = []\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(shape=(N_cols  + KL + w, img.shape[2]), dtype=np.float32)\n",
    "        target_slice_Y = extended_Y[y + KL2:y + KL2 + w, :]\n",
    "        target_slice = extended_img[y + KL2:y + KL2 + w, :]\n",
    "        for i in range(KL):\n",
    "            #horizontal_line += extended_img[y + i, :] * kernel[i]\n",
    "            #horizontal_line += img[(y + i) % img.shape[0], :] * kernel[i]\n",
    "            reference_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            reference_slice = extended_img[y + i:y + i + w, :]\n",
    "            #print(target_slice_Y.shape, reference_slice_Y.shape, w, y, i)\n",
    "            #flow = get_flow(target_slice_Y, reference_slice_Y, l, w, None)\n",
    "            flow = get_flow(reference_slice_Y, target_slice_Y, l, w, None)\n",
    "            #flow = get_flow(reference_slice_Y, reference_slice_Y, l, w, None)\n",
    "            #flow = np.zeros((reference_slice_Y.shape[0], reference_slice_Y.shape[1], 2), dtype=np.float32)\n",
    "            print(flow.shape, reference_slice.shape)\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            #OF_compensated_slice = warp_slice(target_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :, :]\n",
    "            #OF_compensated_line = OF_compensated_slice[0, :, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "        #filtered_img[y, :] = horizontal_line[:]\n",
    "    filtered_img = np.stack(filtered_img, axis=0)\n",
    "    return filtered_img\n",
    "\n",
    "def vertical_OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    w2 = w//2\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    print(f\"KL={KL} l={l} w={w}\")\n",
    "    \n",
    "    # OpciÃ³n 0: Los mÃ¡rgenes son 128\n",
    "    #extended_img = np.full(shape=(img.shape[0] + KL + w, img.shape[1] + w, img.shape[2]), fill_value=128, dtype=np.uint8)\n",
    "    \n",
    "    # OpciÃ³n 1: Usando padding (no terminÃ³ de funcionar)\n",
    "    #extended_img = np.empty(shape=(img.shape[0] + KL + w, img.shape[1] + w, img.shape[2]), dtype=np.uint8)\n",
    "    #extended_img[..., 0] = np.pad(array=img[..., 0],\n",
    "    #                              pad_width=(((KL + w)//2, (KL + w)//2), ((w + 1)//2, (w + 1)//2)),\n",
    "    #                              mode=\"constant\")\n",
    "    #extended_img[..., 1] = np.pad(array=img[..., 1], pad_width=(KL2 + w2, w2), mode=\"constant\")\n",
    "    #extended_img[..., 2] = np.pad(array=img[..., 2], pad_width=(KL2 + w2, w2), mode=\"constant\")\n",
    "    \n",
    "    # OpciÃ³n 2: Los mÃ¡rgenes son la propia imagen, ampliada\n",
    "    extended_img = cv2.resize(src = img, dsize = (img.shape[1] + w, img.shape[0] + KL + w))\n",
    "    print(extended_img.shape)\n",
    "    extended_img[KL2 + w2:img.shape[0] + KL2 + w2, w2:img.shape[1] + w2] = img[...]\n",
    "    extended_Y = YUV.from_RGB(extended_img.astype(np.int16))[..., 0]\n",
    "    filtered_img = []\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(shape=(N_cols + w, img.shape[2]), dtype=np.float32)\n",
    "        target_slice_Y = extended_Y[y + KL2:y + KL2 + w, :]\n",
    "        target_slice = extended_img[y + KL2:y + KL2 + w, :]\n",
    "        for i in range(KL):\n",
    "            reference_slice_Y = extended_Y[y + i:y + i + w, :]\n",
    "            reference_slice = extended_img[y + i:y + i + w, :]\n",
    "            flow = get_flow(reference_slice_Y, target_slice_Y, l, w, None)\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=0)[0:img.shape[0], 0:img.shape[1], :]\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gaussian_kernel(2.0)\n",
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = RGB_image.read(sequence + \"003.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gaussian_kernel(2.0)\n",
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/lena.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show((img - OF_filtered_img + 128).astype(np.uint8),\"\")\n",
    "RGB_image.show((img - filtered_img + 128).astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/Homer.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/sandiego.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/rana.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/calar_alto.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"https://cloudinary-res.cloudinary.com/image/upload/c_fill,w_300/butterfly.jpg\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show((img - OF_filtered_img + 128).astype(np.uint8),\"\")\n",
    "RGB_image.show((img - filtered_img + 128).astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_vertical_OF_gaussian_filtering(img, kernel, l=3, w=5):\n",
    "    KL = kernel.size\n",
    "    KL2 = KL//2\n",
    "    w2 = w//2\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    \n",
    "    # OpciÃ³n 0: Los mÃ¡rgenes son 128\n",
    "    #extended_img = np.full(shape=(img.shape[0] + KL + w, img.shape[1] + w, img.shape[2]), fill_value=128, dtype=np.uint8)\n",
    "    \n",
    "    # OpciÃ³n 1: Usando padding (no terminÃ³ de funcionar)\n",
    "    #extended_img = np.empty(shape=(img.shape[0] + KL + w, img.shape[1] + w, img.shape[2]), dtype=np.uint8)\n",
    "    #extended_img[..., 0] = np.pad(array=img[..., 0],\n",
    "    #                              pad_width=(((KL + w)//2, (KL + w)//2), ((w + 1)//2, (w + 1)//2)),\n",
    "    #                              mode=\"constant\")\n",
    "    #extended_img[..., 1] = np.pad(array=img[..., 1], pad_width=(KL2 + w2, w2), mode=\"constant\")\n",
    "    #extended_img[..., 2] = np.pad(array=img[..., 2], pad_width=(KL2 + w2, w2), mode=\"constant\")\n",
    "    \n",
    "    # OpciÃ³n 2: Los mÃ¡rgenes son la propia imagen, ampliada\n",
    "    extended_img = cv2.resize(src = img, dsize = (img.shape[1] + w, img.shape[0] + KL + w))\n",
    "    print(extended_img.shape)\n",
    "    extended_img[KL2 + w2:img.shape[0] + KL2 + w2, w2:img.shape[1] + w2] = img[...]\n",
    "    extended_Y = extended_img\n",
    "    filtered_img = []\n",
    "    N_rows = img.shape[0]\n",
    "    N_cols = img.shape[1]\n",
    "    for y in range(N_rows):\n",
    "        horizontal_line = np.zeros(shape=(N_cols + w), dtype=np.float32)\n",
    "        target_slice_Y = extended_Y[y + KL2:y + KL2 + w]\n",
    "        target_slice = extended_img[y + KL2:y + KL2 + w]\n",
    "        for i in range(KL):\n",
    "            reference_slice_Y = extended_Y[y + i:y + i + w]\n",
    "            reference_slice = extended_img[y + i:y + i + w]\n",
    "            flow = get_flow(reference_slice_Y, target_slice_Y, l, w, None)\n",
    "            OF_compensated_slice = warp_slice(reference_slice, flow)\n",
    "            OF_compensated_line = OF_compensated_slice[(w + 1) >> 1, :]\n",
    "            horizontal_line += OF_compensated_line * kernel[i]\n",
    "        filtered_img.append(horizontal_line)\n",
    "    filtered_img = np.stack(filtered_img, axis=0)[0:img.shape[0], 0:img.shape[1]]\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/barb.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "gray_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = gray_vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = gray_vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0))\n",
    "filtered_img = gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(img,\"\")\n",
    "gray_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "gray_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"http://www.hpca.ual.es/~vruiz/images/cameraman.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "gray_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = gray_vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = gray_vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0))\n",
    "filtered_img = gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(img,\"\")\n",
    "gray_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "gray_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"https://boofcv.org/images/6/66/Kodim17_noisy.jpg\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)[..., 0]\n",
    "gray_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = gray_vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = gray_vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0))\n",
    "filtered_img = gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(img,\"\")\n",
    "gray_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "gray_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = OF_filtered_img\n",
    "filtered_img_Y = gray_vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = gray_vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(OF_filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from skimage import io as skimage_io\n",
    "\n",
    "fn = \"https://people.math.sc.edu/Burkardt/c_src/image_denoise/balloons_noisy.png\"\n",
    "req = urllib.request.Request(fn, method='HEAD')\n",
    "f = urllib.request.urlopen(req)\n",
    "img = skimage_io.imread(fn)\n",
    "RGB_image.show(img,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow(reference, target, l=3, w=5, prev_flow=None):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=target, next=reference, flow=prev_flow,\n",
    "                                            pyr_scale=0.5, levels=l, winsize=w,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=2.5,\n",
    "                                            flags=0)\n",
    "    return flow\n",
    "\n",
    "kernel = gaussian_kernel(4.0)\n",
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=33)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=33)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))\n",
    "filtered_img = color_gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(img,\"\")\n",
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")\n",
    "RGB_image.show(filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = OF_filtered_img\n",
    "filtered_img_Y = vertical_OF_gaussian_filtering(img, kernel, w=33)\n",
    "filtered_img = vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0, 2)), kernel, w=33)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(OF_filtered_img.astype(np.uint8),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"TwoPhoton_BPAE_B_1.png\"\n",
    "img = cv2.imread(fn, cv2.IMREAD_UNCHANGED)\n",
    "plt.imshow(img)\n",
    "plt.title(\"original\")\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_Y = gray_vertical_OF_gaussian_filtering(img, kernel, w=5)\n",
    "filtered_img = gray_vertical_OF_gaussian_filtering(np.transpose(filtered_img_Y, (1, 0)), kernel, w=5)\n",
    "OF_filtered_img = np.transpose(filtered_img, (1, 0))\n",
    "filtered_img = gaussian_filtering(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filtered_img.astype(np.uint8), cmap='gray')\n",
    "plt.title(f\"Gaussian Filtering\")\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(OF_filtered_img.astype(np.uint8), cmap='gray')\n",
    "plt.title(rf\"OF Gaussian Filtering\")\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.imshow(X=flow_rows2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[3:img.shape[0],:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[3:img.shape[0]+1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create an array of vectors\n",
    "vectors = np.array([[1, 2], [2, 1], [0, 3], [3, 0]])\n",
    "\n",
    "# plot the vectors\n",
    "origin = [0], [0]  # origin point\n",
    "plt.quiver(*origin, vectors[:, 0], vectors[:, 1], color=['r', 'b', 'g', 'y'], scale=10)\n",
    "plt.axis('equal')   # set the aspect ratio to 'equal'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with 1-d lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Y_line = R_Y[..., 1]\n",
    "P_Y_line = P_Y[..., 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_Y_line.shape,P_Y_line.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.stack([np.roll(R_Y_line,-1), R_Y_line, np.roll(R_Y_line,1)])\n",
    "P = np.stack([np.roll(P_Y_line,-1), P_Y_line, np.roll(P_Y_line,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.shape, P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(R[0, i], R[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(P[0, i], P[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(R[0, i], P[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_MVs = np.zeros((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "MVs = motion.Farneback_ME(predicted=P, reference=R, initial_MVs=initial_MVs, wside=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.max(MVs[1]), np.min(MVs[1]), np.argmax(MVs[1]), MVs[np.argmax(MVs[1])])\n",
    "print(np.max(MVs[1]), np.min(MVs[1]), len(MVs[1]), np.argmax(MVs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(P.shape[1]):\n",
    "    print(i, R[1, i], P[1, i], MVs[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.arange(4).astype(np.int16)\n",
    "block = np.stack([line, line, line, line])\n",
    "print(block)\n",
    "#block = np.arange(16).astype(np.int16).reshape(4, 4)\n",
    "c = np.ones_like(block)\n",
    "A, B, C = poly_exp(block, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FarnebÃ¤ck basis transform\n",
    "FarnebÃ¤ck's algorithm does not compare pixels, but polinomial coefficients (each pixel generates 6 coefficients) using Polinomial Expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = np.sin(tau)**2+np.cos(tau)**2+0.005\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'1')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant motion in the X direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$y$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp, cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant motion in the Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$x$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contant motion in both directions (at the same time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau*phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$xy$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant acceleration in the Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = tau*tau\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$x^2$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant acceleration in the X direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax3d = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make the X, Y meshgrid instead of np.tile\n",
    "xs = np.linspace(-100, 100, 200)\n",
    "ys = np.linspace(-100, 100, 200)\n",
    "tau, phi = np.meshgrid(xs, ys) \n",
    "# Z evaluation\n",
    "amp = phi*phi\n",
    "\n",
    "ax3d.set_xlabel(r'$x$')  # tau = omega*t -> adimensional time\n",
    "ax3d.set_ylabel(r'$y$')  # phi -> phase\n",
    "ax3d.set_zlabel(r'$z$')   # signal amplitude\n",
    "ax3d.set_title(r'$y^2$')   # signal amplitude\n",
    "\n",
    "surf = ax3d.plot_surface(tau, phi, amp,cmap=cm.inferno)\n",
    "#fig.colorbar(surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farneback 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp_1D(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 1D signal.\n",
    "    \n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    \n",
    "    If f[i] and c[i] are the signal value and certainty of pixel i then\n",
    "    A[i] is a 1x1 array representing the quadratic term of the polynomial, B[i]\n",
    "    is a 1-element array representing the linear term, and C[i] is a scalar\n",
    "    representing the constant term.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    # Kernel applicability\n",
    "    n = int(4 * sigma + 1)\n",
    "    print(\"n =\", n)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    print(\"x =\", x)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))\n",
    "    print(\"a =\", a)\n",
    "\n",
    "    # b: calculate b from the paper.\n",
    "    b = np.stack([np.ones(a.shape), x, x**2], axis=-1)\n",
    "    print(\"b =\", b)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "    print(\"f =\", f)\n",
    "    print(\"c =\", c)\n",
    "    print(\"cf =\", cf)\n",
    "    \n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [b.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [b.shape[-1]])\n",
    "\n",
    "    #G = np.empty(list(f.shape))\n",
    "    #v = np.empty(list(f.shape))\n",
    "    print(\"G.shape =\", G.shape)\n",
    "    print(\"v.shape =\", v.shape)\n",
    "\n",
    "    # Apply cross-correlation\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, b) # a[i]*b[i,j] -> ab[i,j]\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, b) # ab[i,j]*b[i,k] -> abb[i,j,k]\n",
    "    print(\"ab =\", ab)\n",
    "    print(\"abb =\", abb)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(b.shape[-1]):\n",
    "        for j in range(b.shape[-1]):\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "    #for j in range(b.shape[-1]):\n",
    "    #    G[..., j] = scipy.ndimage.correlate1d(\n",
    "    #        c, abb[..., j], axis=0, mode=\"constant\", cval=0\n",
    "    #    )\n",
    "    print(\"G =\", G)\n",
    "    print(\"v =\", v)\n",
    "\n",
    "    #v = scipy.ndimage.correlate1d(\n",
    "    #    cf, ab, axis=0, mode=\"constant\", cval=0\n",
    "    #)\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "    print(\"r =\", r)\n",
    "\n",
    "    # Quadratic term\n",
    "    #A = np.empty(list(f.shape))\n",
    "    A = np.empty(list(f.shape)  + [1])\n",
    "    A[..., 0] = r[..., 2]\n",
    "    print(\"A =\", A)\n",
    "\n",
    "    # Linear term\n",
    "    #B = np.empty(list(f.shape))\n",
    "    B = np.empty(list(f.shape) + [1])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    print(\"B =\", B)\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "    print(\"C =\", C)\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    print(\"A.shape, B.shape, C.shape =\", A.shape, B.shape, C.shape)\n",
    "    return A, B, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.arange(4).astype(np.int16)\n",
    "c = np.ones_like(line)\n",
    "A, B, C = poly_exp_1D(line, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative_1D(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First image\n",
    "    f2\n",
    "        Second image\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first image\n",
    "    c2\n",
    "        Certainty of second image\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i, j] is the (y, x) displacement for pixel (i, j)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the lines\n",
    "    A1, B1, C1 = poly_exp_1D(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp_1D(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images\n",
    "    x = np.arange(f1.shape[0]).astype(np.int32)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [1])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(np.int32)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        print(x_.shape, np.array(f1.shape))\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2)\n",
    "        ATA = S_T @ A_T @ A @ S\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # \n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0, 1))\n",
    "            h_avg = np.mean(ATb, axis=(0, 1))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = np.arange(16).astype(np.int16).reshape(4, 4)\n",
    "f2 = np.arange(16).astype(np.int16).reshape(4, 4)\n",
    "sigma = 1.0\n",
    "c1 = np.ones_like(f1)\n",
    "c2 = np.ones_like(f2)\n",
    "sigma_flow = 1.0\n",
    "flow_iterative_1D(f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = np.arange(16).astype(np.int16).reshape(4, 4)\n",
    "f2 = np.arange(16).astype(np.int16).reshape(4, 4)\n",
    "x = np.stack(np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])), axis=-1,).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(2).swapaxes(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.ones_like(R_Y_line)\n",
    "print(c.shape)\n",
    "A, B, C = poly_exp_1D(R_Y_line, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
