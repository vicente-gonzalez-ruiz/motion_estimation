{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada85c9c-8892-4ce0-849f-ecc5b3ca234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s %(funcName)s()] %(message)s\")\n",
    "#logger.setLevel(logging.CRITICAL)\n",
    "#logger.setLevel(logging.ERROR)\n",
    "#logger.setLevel(logging.WARNING)\n",
    "logger.setLevel(logging.INFO)\n",
    "#logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b74b2-30f1-4d13-bef4-ccde0e7e1558",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8a37e-f24f-42df-8120-a05d72565ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motion_estimation._1D.polinomial_expansion as PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b29f6f-8f02-4690-8df4-318bccfe63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE.Polinomial_Expansion(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd73a48-81ec-4301-988b-7380eb0f9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.arange(40).astype(np.uint8)\n",
    "#line = np.ones(shape=4, dtype=np.uint8)\n",
    "print(line)\n",
    "c = np.ones_like(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe113a-e8c5-44b1-89ed-9da3b0ee7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = pe.expand(line, c, window_length=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c856b44-2c8c-4f19-83f0-a66606340a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8da90-6e21-4fde-a366-18d458ab7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b231942-71bc-432a-ad95-6989262fdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310011c-affd-454f-a1ed-1216d4aca248",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a3926-ea10-49c3-8e1f-5db6802288de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motion_estimation._2D.polinomial_expansion as PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574fbcf-3a1a-479b-8867-db0f93444744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE.Polinomial_Expansion(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c140fe-b285-4d9b-a245-dcec6adaccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import skimage.io\n",
    "#img = skimage.io.imread(\"http://www.hpca.ual.es/~vruiz/images/barb.png\")\n",
    "#img = np.random.randint(low=0, high=255, size=(4,3), dtype=np.uint8)\n",
    "#img = np.ones(shape=(4,3), dtype=np.uint8)\n",
    "img = np.stack([line, line, line]).T\n",
    "#img = img[:, 0:3]\n",
    "print(img)\n",
    "c = np.ones_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd31aa-50d3-4e6c-9394-f657eb76ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = pe.expand(img, c, window_side=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22941e3d-41b9-47a0-a76c-08d3d922f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c64047-1f37-44d0-91db-1fcb3ad559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bfde1-d241-40bd-99fa-1b741e627f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp_1D(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 1D signal.\n",
    "    \n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    \n",
    "    If f[i] and c[i] are the signal value and certainty of sample i then\n",
    "    A[i] is a 1x1 array representing the quadratic term of the polynomial, B[i]\n",
    "    is a 1-element array representing the linear term, and C[i] is a scalar\n",
    "    representing the constant term.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    #print(\"f\", f)\n",
    "    #print(\"c\", c)\n",
    "    # Kernel applicability (gaussian)\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))\n",
    "\n",
    "    # b: calculate b from the paper.\n",
    "    b = np.stack([np.ones(a.shape), x, x**2], axis=-1)\n",
    "    #print(\"b.shape\", b.shape)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [b.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [b.shape[-1]])\n",
    "    #print(\"G.shape =\", G.shape)\n",
    "    #print(\"v.shape =\", v.shape)\n",
    "\n",
    "    # Apply cross-correlation\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, b) # ab[i] = b[i]*a[i]\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, b) # abb[i,j] = ab[i]*b[j]\n",
    "    #print(\"a\", a)\n",
    "    #print(\"b\", b)\n",
    "    #print(\"ab\", ab)\n",
    "    #print(\"abb\", abb)\n",
    "    #print(\"ab.shape\", ab.shape)\n",
    "    #print(\"abb.shape\", abb.shape)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(b.shape[-1]):\n",
    "        for j in range(b.shape[-1]):\n",
    "            #print(\"G[..., i, j].shape\", G[..., i, j].shape)\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "    '''\n",
    "    print(\"b.shape[-1]\", b.shape[-1])\n",
    "    for j in range(b.shape[-1]):\n",
    "        print(\"weights\", abb[..., j])\n",
    "        print(\"c\", c)\n",
    "        print(\"abb[..., j]\", abb[..., j])\n",
    "        print(\"G[..., j]\", G[..., j])\n",
    "        G[..., j][0] = scipy.ndimage.correlate1d(\n",
    "            c, abb[..., j][0], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "    v = scipy.ndimage.correlate1d(\n",
    "        cf, ab, axis=0, mode=\"constant\", cval=0\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [1, 1])\n",
    "    A[..., 0, 0] = r[..., 2]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [1])\n",
    "    B[..., 0] = r[..., 1]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e73c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = poly_exp_1D(line, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145b5b5-20bc-475c-8465-d3278685e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5b2d2-33b3-4263-8020-685e5bd2e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2e2b4-a929-4b50-af73-be9a8b3225f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09861b-01d8-4a78-8d70-28518b4aaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative_1d(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First signal\n",
    "    f2\n",
    "        Second signal\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first signal\n",
    "    c2\n",
    "        Certainty of second signal\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i] is the x displacement for sample i\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each sample in the signals\n",
    "    A1, B1, C1 = poly_exp_1D(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp_1D(f2, c2, sigma)\n",
    "\n",
    "    # Sample indexes in the signals\n",
    "    x = np.arange(f1.shape[0])[:, None].astype(int)\n",
    "    #print(x)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [1])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(1)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2) # Without effect in 1D\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0]]) / 2  # Eq. 7.12 (see also Fig. 7.8)\n",
    "        #print(A1, A2)\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        #print(A.shape, d_[..., None].shape)\n",
    "        delB = -1 / 2 * (B2[x_[..., 0]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2) # Without effect in 1D\n",
    "        ATA = S_T @ A_T @ A @ S # G(x) in the thesis (see Fig. 7.8)\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0] # h(x) in the thesis (see Fig. 7.8)\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # if mu is not 0, it should be used to regularize the least squares problem\n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0))\n",
    "            h_avg = np.mean(ATb, axis=(0))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            #G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            #h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(1), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d\n",
    "\n",
    "flow_iterative_1d(f1=line, f2=np.roll(line,0), sigma=2.0, c1=c, c2=c, sigma_flow=2.0, num_iter=3, d=None, model=\"constant\", mu=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c68433-751e-4876-88be-b435f2b2fc1e",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecddc5-cc2e-4bbc-86cc-241431c723c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "#img = skimage.io.imread(\"http://www.hpca.ual.es/~vruiz/images/barb.png\")\n",
    "#img = np.random.randint(low=0, high=255, size=(4,3), dtype=np.uint8)\n",
    "#img = np.ones(shape=(4,3), dtype=np.uint8)\n",
    "img = np.stack([line, line, line]).T\n",
    "#img = img[:, 0:3]\n",
    "print(img)\n",
    "c = np.ones_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 2D signal, as described by Farneback\n",
    "    Uses separable normalized correlation\n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    If f[i, j] and c[i, j] are the signal value and certainty of pixel (i, j) then\n",
    "    A[i, j] is a 2x2 array representing the quadratic term of the polynomial, B[i, j]\n",
    "    is a 2-element array representing the linear term, and C[i, j] is a scalar\n",
    "    representing the constant term.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    # Calculate applicability kernel (1D because it is separable)\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))  # a: applicability kernel [n]\n",
    "    #print(\"a.shape\", a.shape)\n",
    "\n",
    "    # b: calculate b from the paper. Calculate separately for X and Y dimensions\n",
    "    # [n, 6]\n",
    "    bx = np.stack(\n",
    "        [np.ones(a.shape), x, np.ones(a.shape), x**2, np.ones(a.shape), x], axis=-1\n",
    "    )\n",
    "    by = np.stack(\n",
    "        [np.ones(a.shape), np.ones(a.shape), x, np.ones(a.shape), x**2, x, ], axis=-1,\n",
    "    )\n",
    "    #print(\"bx.shape\", bx.shape)\n",
    "    #print(\"by.shape\", by.shape)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "    #print(\"cf.shape\", cf.shape)\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r (see Eq. 4.9 of the thesis)\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [bx.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [bx.shape[-1]])\n",
    "    #print(\"G.shape\", G.shape)\n",
    "    #print(\"v.shape\", v.shape)\n",
    "\n",
    "    # Apply separable cross-correlations\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper (Eq. 4.6 in the thesis)\n",
    "    ab = np.einsum(\"i,ij->ij\", a, bx) # ab[i,j] = bx[i,j]*a[i] (multiply each row of \"bx\" by the corresponding element of \"a\")\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, bx) # abb[i,j,k] = ab[i,j]*bx[j,k]\n",
    "    #print(\"a\", a, a.shape)\n",
    "    #print(\"bx\", bx, bx.shape)\n",
    "    #print(\"ab\", ab)\n",
    "    #print(\"abb\", abb)\n",
    "    #print(\"ab.shape\", ab.shape)\n",
    "    #print(\"abb.shape\", abb.shape)\n",
    "    \n",
    "    # Calculate G and v for each pixel with cross-correlation (axis 0)\n",
    "    #print(\"bx.shape[-1]\", bx.shape[-1])\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            #print(\"G[..., i, j].shape\", G[..., i, j].shape)\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, by)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, by)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation (axis 1)\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                G[..., i, j], abb[..., i, j], axis=1, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            v[..., i], ab[..., i], axis=1, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Solve r for each pixel (eq. 4.8 of the thesis)\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [2, 2])\n",
    "    A[..., 0, 0] = r[..., 3]\n",
    "    A[..., 0, 1] = r[..., 5] / 2\n",
    "    A[..., 1, 0] = A[..., 0, 1]\n",
    "    A[..., 1, 1] = r[..., 4]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [2])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    B[..., 1] = r[..., 2]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f70a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = poly_exp(img, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cb055-6d72-42b6-b871-422cb7051c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041539-90bb-436f-b6ff-33e4578df9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00eb10-afcb-45f7-9542-53c35419c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First image\n",
    "    f2\n",
    "        Second image\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first image\n",
    "    c2\n",
    "        Certainty of second image\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i, j] is the (y, x) displacement for pixel (i, j)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the images\n",
    "    A1, B1, C1 = poly_exp(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images\n",
    "    x = np.stack(\n",
    "        np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])),\n",
    "        axis=-1,\n",
    "    ).astype(int)\n",
    "    print(f1.shape)\n",
    "    print(np.arange(f1.shape[0]))\n",
    "    print(np.arange(f1.shape[0])[:, None])\n",
    "    print(np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])))\n",
    "    print(x)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [2])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        print(A1, A2[x_[..., 0], x_[..., 1]])\n",
    "\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2)\n",
    "        ATA = S_T @ A_T @ A @ S\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # if mu is not 0, it should be used to regularize the least squares problem\n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0, 1))\n",
    "            h_avg = np.mean(ATb, axis=(0, 1))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d\n",
    "\n",
    "flow_iterative(f1=img, f2=img, sigma=1.0, c1=c, c2=c, sigma_flow=1.0, num_iter=1, d=None, model=\"constant\", mu=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c33cc-7a73-4b46-a9cc-96922d1876a2",
   "metadata": {},
   "source": [
    "## 1D version (ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d525db9-c755-4c48-96d7-9afec88f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp_1d(signal, certainty, sigma): # probando\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Calculate applicability kernel (1D)\n",
    "    ab = np.einsum(\"i,j->ij\", a, x)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, x)\n",
    "    \n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = certainty * signal\n",
    "    \n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty_like(abb)\n",
    "    v = np.empty_like(ab)\n",
    "    \n",
    "    # Apply separable cross-correlations\n",
    "    for i in range(ab.shape[-1]):\n",
    "        G[..., i] = scipy.ndimage.correlate1d(certainty, abb[..., i], mode=\"constant\", cval=0)\n",
    "        v[..., i] = scipy.ndimage.correlate1d(cf, ab[..., i], mode=\"constant\", cval=0)\n",
    "    \n",
    "    # Solve r for each pixel (eq. 4.8 of the thesis)\n",
    "    r = np.linalg.solve(G, v)\n",
    "    \n",
    "    # Quadratic term\n",
    "    A = np.empty((2, 2))\n",
    "    A[0, 0] = r[3]\n",
    "    A[0, 1] = r[5] / 2\n",
    "    A[1, 0] = A[0, 1]\n",
    "    A[1, 1] = r[4]\n",
    "    \n",
    "    # Linear term\n",
    "    B = np.empty(2)\n",
    "    B[0] = r[1]\n",
    "    B[1] = r[2]\n",
    "    \n",
    "    # Constant term\n",
    "    C = r[0]\n",
    "    \n",
    "    return A, B, C\n",
    "\n",
    "def flow_iterative_1d(signal1, signal2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None):\n",
    "    # Calculate the polynomial expansion at each point in the signals\n",
    "    A1, B1, C1 = poly_exp_1d(signal1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp_1d(signal2, c2, sigma)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(2)\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel\n",
    "        d_ = d.astype(int)\n",
    "        \n",
    "        # Apply separable cross-correlation to calculate linear equation for each pixel\n",
    "        G = scipy.ndimage.correlate1d(A1 + A2, w, mode=\"constant\", cval=0)\n",
    "        h = scipy.ndimage.correlate1d(B2 - B1 + (A1 @ d_[..., None])[..., 0], w, mode=\"constant\", cval=0)\n",
    "\n",
    "        # Solve linear equation for each pixel\n",
    "        d = np.linalg.solve(G, h)\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Example usage:\n",
    "signal1 = np.array([1, 2, 3, 4, 5])\n",
    "signal2 = np.array([2, 3, 4, 5, 6])\n",
    "certainty1 = np.array([0.9, 0.8, 0.7, 0.6, 0.5])\n",
    "certainty2 = np.array([0.9, 0.8, 0.7, 0.6, 0.5])\n",
    "\n",
    "result = flow_iterative_1d(signal1, signal2, sigma=1.0, c1=certainty1, c2=certainty2, sigma_flow=1.0, num_iter=1, d=None, model=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3580f0-daa2-4779-8490-4522102ddcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
