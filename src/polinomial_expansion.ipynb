{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada85c9c-8892-4ce0-849f-ecc5b3ca234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s %(funcName)s()] %(message)s\")\n",
    "#logger.setLevel(logging.CRITICAL)\n",
    "#logger.setLevel(logging.ERROR)\n",
    "#logger.setLevel(logging.WARNING)\n",
    "logger.setLevel(logging.INFO)\n",
    "#logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b74b2-30f1-4d13-bef4-ccde0e7e1558",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8a37e-f24f-42df-8120-a05d72565ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motion_estimation._1D.polinomial_expansion as PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b29f6f-8f02-4690-8df4-318bccfe63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE.Polinomial_Expansion(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea27fe-08ef-492d-9693-0643d21c9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_gaussian(size, sigma, mu=0):\n",
    "    \"\"\"Generate a 1D Gaussian function sampled in a 1D NumPy array.\n",
    "    \n",
    "    Args:\n",
    "        size (int): The size of the 1D array (size).\n",
    "        sigma (float): The standard deviation of the Gaussian.\n",
    "        mu (float): The mean of the Gaussian. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A 1D array containing the sampled Gaussian function.\n",
    "    \"\"\"\n",
    "    # Create a coordinate grid\n",
    "    x = np.linspace(-size // 2, size // 2, size)\n",
    "\n",
    "    # Calculate the 2D Gaussian function\n",
    "    gaussian_1d = np.exp(-((x - mu)**2) / (2 * sigma**2))\n",
    "\n",
    "    return gaussian_1d\n",
    "\n",
    "# Example usage\n",
    "size = 100  # Define the size of the 2D array\n",
    "sigma = 10.0  # Define the standard deviation of the Gaussian\n",
    "line = generate_1d_gaussian(size, sigma)\n",
    "c = np.ones_like(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed579c0-433b-4a79-942d-56981b529aca",
   "metadata": {},
   "source": [
    "line = np.arange(40).astype(np.uint8)\n",
    "#line = np.ones(shape=4, dtype=np.uint8)\n",
    "print(line)\n",
    "c = np.ones_like(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8e3fd-84f4-4910-8d9b-ad00cd9c0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe113a-e8c5-44b1-89ed-9da3b0ee7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = pe.expand(line, c, window_length=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e730a74-15bf-465b-981e-edc230dae92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d6a8e-19e8-46fd-93da-35bc9d199f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4444c-8cb3-407b-a1a7-16aefb261eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d5b21-e991-48eb-9bb4-29e93401e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(B[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b231942-71bc-432a-ad95-6989262fdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e106f-0e4e-4b8c-b1ee-22c2bae6eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310011c-affd-454f-a1ed-1216d4aca248",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753bf6e-5bcc-431d-8488-c09c66f4568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_gaussian(size, sigma, mu=0):\n",
    "    \"\"\"Generate a 2D Gaussian function sampled in a 2D NumPy array.\n",
    "    \n",
    "    Args:\n",
    "        size (int): The size of the 2D array (size x size).\n",
    "        sigma (float): The standard deviation of the Gaussian.\n",
    "        mu (float): The mean of the Gaussian. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A 2D array containing the sampled Gaussian function.\n",
    "    \"\"\"\n",
    "    # Create a coordinate grid\n",
    "    x = np.linspace(-size // 2, size // 2, size)\n",
    "    y = np.linspace(-size // 2, size // 2, size)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    # Calculate the 2D Gaussian function\n",
    "    gaussian_2d = np.exp(-((x - mu)**2 + (y - mu)**2) / (2 * sigma**2))\n",
    "\n",
    "    return gaussian_2d\n",
    "\n",
    "# Example usage\n",
    "size = 100  # Define the size of the 2D array\n",
    "sigma = 10.0  # Define the standard deviation of the Gaussian\n",
    "img = generate_2d_gaussian(size, sigma)\n",
    "c = np.ones_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d817cd5-781a-4abd-ae9c-a7954fa79948",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a3926-ea10-49c3-8e1f-5db6802288de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motion_estimation._2D.polinomial_expansion as PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574fbcf-3a1a-479b-8867-db0f93444744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE.Polinomial_Expansion(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3225f-1821-482e-a9bd-e8ec5d60333b",
   "metadata": {},
   "source": [
    "#import skimage.io\n",
    "#img = skimage.io.imread(\"http://www.hpca.ual.es/~vruiz/images/barb.png\")\n",
    "#img = np.random.randint(low=0, high=255, size=(4,3), dtype=np.uint8)\n",
    "#img = np.ones(shape=(4,3), dtype=np.uint8)\n",
    "img = np.stack([line, line, line]).T\n",
    "#img = img[:, 0:3]\n",
    "print(img)\n",
    "c = np.ones_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f47ad-92e2-43e7-855f-d2e7d16ac5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd31aa-50d3-4e6c-9394-f657eb76ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = pe.expand(img, c, window_side=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f268e-5197-4359-adf1-ca2e01f78e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6df5ca-8508-46b7-b05e-f85a84e56811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f5fd6-1da1-45b0-92fd-ba1d171c018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142c68a-dac8-49d5-96a3-9e44c80fab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22941e3d-41b9-47a0-a76c-08d3d922f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e72ea7-ebc7-4630-9dd5-56dda1661699",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c26211-513d-47ec-8cad-4553ed4745b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B[:,:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0659308-57ad-41d3-a5a7-28833bdf4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B[:,:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19dcd32-97c2-486c-9328-18853e6dc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8f991-668d-44c7-b222-faa21de4aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253d6d6-f1c2-4afe-b6d8-c3578761e927",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7f06b-d02a-4f26-ae28-68156bdc10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_gaussian(size, sigma, mu=0):\n",
    "    \"\"\"Generate a 3D Gaussian function sampled in a 3D NumPy array.\n",
    "    \n",
    "    Args:\n",
    "        size (int): The size of the 3D array (size x size x size).\n",
    "        sigma (float): The standard deviation of the Gaussian.\n",
    "        mu (float): The mean of the Gaussian. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A 3D array containing the sampled Gaussian function.\n",
    "    \"\"\"\n",
    "    # Create a coordinate grid\n",
    "    x = np.linspace(-size // 2, size // 2, size)\n",
    "    y = np.linspace(-size // 2, size // 2, size)\n",
    "    z = np.linspace(-size // 2, size // 2, size)\n",
    "    x, y, z = np.meshgrid(x, y, z)\n",
    "\n",
    "    # Calculate the 2D Gaussian function\n",
    "    gaussian_3d = np.exp(-((x - mu)**2 + (y - mu)**2  + (z - mu)**2) / (2 * sigma**2))\n",
    "\n",
    "    return gaussian_3d\n",
    "\n",
    "# Example usage\n",
    "size = 100  # Define the size of the 2D array\n",
    "sigma = 10.0  # Define the standard deviation of the Gaussian\n",
    "vol = generate_3d_gaussian(size, sigma)\n",
    "c = np.ones_like(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358eb10-5c43-4dfe-989f-defd5da8f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vol[50, 50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52730c41-d8a6-49b9-9ad7-3c2388916945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vol[:, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f0b78-6e3e-4a2c-b9aa-051d325e5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vol[50, 50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7b0b8-b025-41ac-a5ae-9bf199757330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motion_estimation._3D.polinomial_expansion as PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71720769-4a11-4ae6-89c8-00f0b796af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE.Polinomial_Expansion(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733a950-2cbe-4a40-8763-663731d4b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = pe.expand(vol, c, window_side=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60736caa-1de1-4502-927d-512353759c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf002a-aea6-4517-b2d8-80fa77ef28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd444f62-9618-4282-a13e-8666e004b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc404e6d-139e-438a-a53c-1dfd784a5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65262a1-27ac-4ef9-9654-4a2fe34e6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646cff4-1d39-4759-a162-a3cffbb0ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30838f9d-181b-4e0e-b6d1-80dbaa1612c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6745fa6-f825-4e3f-b519-e3f97124d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb8a4b-654b-4b8f-942e-c1e9cdab34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3ff7b-e4aa-4b40-8b65-05bddc6329e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[:,:,50, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c863f3-3c2d-45d7-821b-8f74c0541a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp_1D(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 1D signal.\n",
    "    \n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    \n",
    "    If f[i] and c[i] are the signal value and certainty of sample i then\n",
    "    A[i] is a 1x1 array representing the quadratic term of the polynomial, B[i]\n",
    "    is a 1-element array representing the linear term, and C[i] is a scalar\n",
    "    representing the constant term.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    #print(\"f\", f)\n",
    "    #print(\"c\", c)\n",
    "    # Kernel applicability (gaussian)\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))\n",
    "\n",
    "    # b: calculate b from the paper.\n",
    "    b = np.stack([np.ones(a.shape), x, x**2], axis=-1)\n",
    "    #print(\"b.shape\", b.shape)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [b.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [b.shape[-1]])\n",
    "    #print(\"G.shape =\", G.shape)\n",
    "    #print(\"v.shape =\", v.shape)\n",
    "\n",
    "    # Apply cross-correlation\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, b) # ab[i] = b[i]*a[i]\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, b) # abb[i,j] = ab[i]*b[j]\n",
    "    #print(\"a\", a)\n",
    "    #print(\"b\", b)\n",
    "    #print(\"ab\", ab)\n",
    "    #print(\"abb\", abb)\n",
    "    #print(\"ab.shape\", ab.shape)\n",
    "    #print(\"abb.shape\", abb.shape)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(b.shape[-1]):\n",
    "        for j in range(b.shape[-1]):\n",
    "            #print(\"G[..., i, j].shape\", G[..., i, j].shape)\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "    '''\n",
    "    print(\"b.shape[-1]\", b.shape[-1])\n",
    "    for j in range(b.shape[-1]):\n",
    "        print(\"weights\", abb[..., j])\n",
    "        print(\"c\", c)\n",
    "        print(\"abb[..., j]\", abb[..., j])\n",
    "        print(\"G[..., j]\", G[..., j])\n",
    "        G[..., j][0] = scipy.ndimage.correlate1d(\n",
    "            c, abb[..., j][0], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "    v = scipy.ndimage.correlate1d(\n",
    "        cf, ab, axis=0, mode=\"constant\", cval=0\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [1, 1])\n",
    "    A[..., 0, 0] = r[..., 2]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [1])\n",
    "    B[..., 0] = r[..., 1]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e73c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = poly_exp_1D(line, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145b5b5-20bc-475c-8465-d3278685e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5b2d2-33b3-4263-8020-685e5bd2e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2e2b4-a929-4b50-af73-be9a8b3225f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09861b-01d8-4a78-8d70-28518b4aaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative_1d(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First signal\n",
    "    f2\n",
    "        Second signal\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first signal\n",
    "    c2\n",
    "        Certainty of second signal\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i] is the x displacement for sample i\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each sample in the signals\n",
    "    A1, B1, C1 = poly_exp_1D(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp_1D(f2, c2, sigma)\n",
    "\n",
    "    # Sample indexes in the signals\n",
    "    x = np.arange(f1.shape[0])[:, None].astype(int)\n",
    "    #print(x)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [1])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(1)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2) # Without effect in 1D\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0]]) / 2  # Eq. 7.12 (see also Fig. 7.8)\n",
    "        #print(A1, A2)\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        #print(A.shape, d_[..., None].shape)\n",
    "        delB = -1 / 2 * (B2[x_[..., 0]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2) # Without effect in 1D\n",
    "        ATA = S_T @ A_T @ A @ S # G(x) in the thesis (see Fig. 7.8)\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0] # h(x) in the thesis (see Fig. 7.8)\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # if mu is not 0, it should be used to regularize the least squares problem\n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0))\n",
    "            h_avg = np.mean(ATb, axis=(0))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            #G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            #h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(1), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d\n",
    "\n",
    "flow_iterative_1d(f1=line, f2=np.roll(line,0), sigma=2.0, c1=c, c2=c, sigma_flow=2.0, num_iter=3, d=None, model=\"constant\", mu=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c68433-751e-4876-88be-b435f2b2fc1e",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecddc5-cc2e-4bbc-86cc-241431c723c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "#img = skimage.io.imread(\"http://www.hpca.ual.es/~vruiz/images/barb.png\")\n",
    "#img = np.random.randint(low=0, high=255, size=(4,3), dtype=np.uint8)\n",
    "#img = np.ones(shape=(4,3), dtype=np.uint8)\n",
    "img = np.stack([line, line, line]).T\n",
    "#img = img[:, 0:3]\n",
    "print(img)\n",
    "c = np.ones_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp(f, c, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the local polynomial expansion of a 2D signal, as described by Farneback\n",
    "    Uses separable normalized correlation\n",
    "    $f ~ x^T A x + B^T x + C$\n",
    "    If f[i, j] and c[i, j] are the signal value and certainty of pixel (i, j) then\n",
    "    A[i, j] is a 2x2 array representing the quadratic term of the polynomial, B[i, j]\n",
    "    is a 2-element array representing the linear term, and C[i, j] is a scalar\n",
    "    representing the constant term.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f\n",
    "        Input signal\n",
    "    c\n",
    "        Certainty of signal\n",
    "    sigma\n",
    "        Standard deviation of applicability Gaussian kernel\n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "        Quadratic term of polynomial expansion\n",
    "    B\n",
    "        Linear term of polynomial expansion\n",
    "    C\n",
    "        Constant term of polynomial expansion\n",
    "    \"\"\"\n",
    "    # Calculate applicability kernel (1D because it is separable)\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))  # a: applicability kernel [n]\n",
    "    #print(\"a.shape\", a.shape)\n",
    "\n",
    "    # b: calculate b from the paper. Calculate separately for X and Y dimensions\n",
    "    # [n, 6]\n",
    "    bx = np.stack(\n",
    "        [np.ones(a.shape), x, np.ones(a.shape), x**2, np.ones(a.shape), x], axis=-1\n",
    "    )\n",
    "    by = np.stack(\n",
    "        [np.ones(a.shape), np.ones(a.shape), x, np.ones(a.shape), x**2, x, ], axis=-1,\n",
    "    )\n",
    "    #print(\"bx.shape\", bx.shape)\n",
    "    #print(\"by.shape\", by.shape)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = c * f\n",
    "    #print(\"cf.shape\", cf.shape)\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r (see Eq. 4.9 of the thesis)\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [bx.shape[-1]] * 2)\n",
    "    v = np.empty(list(f.shape) + [bx.shape[-1]])\n",
    "    #print(\"G.shape\", G.shape)\n",
    "    #print(\"v.shape\", v.shape)\n",
    "\n",
    "    # Apply separable cross-correlations\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper (Eq. 4.6 in the thesis)\n",
    "    ab = np.einsum(\"i,ij->ij\", a, bx) # ab[i,j] = bx[i,j]*a[i] (multiply each row of \"bx\" by the corresponding element of \"a\")\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, bx) # abb[i,j,k] = ab[i,j]*bx[j,k]\n",
    "    #print(\"a\", a, a.shape)\n",
    "    #print(\"bx\", bx, bx.shape)\n",
    "    #print(\"ab\", ab)\n",
    "    #print(\"abb\", abb)\n",
    "    #print(\"ab.shape\", ab.shape)\n",
    "    #print(\"abb.shape\", abb.shape)\n",
    "    \n",
    "    # Calculate G and v for each pixel with cross-correlation (axis 0)\n",
    "    #print(\"bx.shape[-1]\", bx.shape[-1])\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            #print(\"G[..., i, j].shape\", G[..., i, j].shape)\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                c, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            cf, ab[..., i], axis=0, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", a, by)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, by)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation (axis 1)\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = scipy.ndimage.correlate1d(\n",
    "                G[..., i, j], abb[..., i, j], axis=1, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = scipy.ndimage.correlate1d(\n",
    "            v[..., i], ab[..., i], axis=1, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Solve r for each pixel (eq. 4.8 of the thesis)\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [2, 2])\n",
    "    A[..., 0, 0] = r[..., 3]\n",
    "    A[..., 0, 1] = r[..., 5] / 2\n",
    "    A[..., 1, 0] = A[..., 0, 1]\n",
    "    A[..., 1, 1] = r[..., 4]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [2])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    B[..., 1] = r[..., 2]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f70a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = poly_exp(img, c, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cb055-6d72-42b6-b871-422cb7051c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041539-90bb-436f-b6ff-33e4578df9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00eb10-afcb-45f7-9542-53c35419c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative(\n",
    "    f1, f2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates optical flow with an algorithm described by Gunnar Farneback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f1\n",
    "        First image\n",
    "    f2\n",
    "        Second image\n",
    "    sigma\n",
    "        Polynomial expansion applicability Gaussian kernel sigma\n",
    "    c1\n",
    "        Certainty of first image\n",
    "    c2\n",
    "        Certainty of second image\n",
    "    sigma_flow\n",
    "        Applicability window Gaussian kernel sigma for polynomial matching\n",
    "    num_iter\n",
    "        Number of iterations to run (defaults to 1)\n",
    "    d: (optional)\n",
    "        Initial displacement field\n",
    "    p: (optional)\n",
    "        Initial global displacement model parameters\n",
    "    model: ['constant', 'affine', 'eight_param']\n",
    "        Optical flow parametrization to use\n",
    "    mu: (optional)\n",
    "        Weighting term for usage of global parametrization. Defaults to\n",
    "        using value recommended in Farneback's thesis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "        Optical flow field. d[i, j] is the (y, x) displacement for pixel (i, j)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the images\n",
    "    A1, B1, C1 = poly_exp(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images\n",
    "    x = np.stack(\n",
    "        np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])),\n",
    "        axis=-1,\n",
    "    ).astype(int)\n",
    "    print(f1.shape)\n",
    "    print(np.arange(f1.shape[0]))\n",
    "    print(np.arange(f1.shape[0])[:, None])\n",
    "    print(np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])))\n",
    "    print(x)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [2])\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        print(A1, A2[x_[..., 0], x_[..., 1]])\n",
    "\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        # Pre-calculate quantities recommended by paper\n",
    "        A_T = A.swapaxes(-1, -2)\n",
    "        ATA = S_T @ A_T @ A @ S\n",
    "        ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "        # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "        # If mu is 0, it means the global/average parametrized warp should not be\n",
    "        # calculated, and the parametrization should apply to the local calculations\n",
    "        if mu == 0:\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            # for each pixel: G*d = h\n",
    "            G = scipy.ndimage.correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "\n",
    "        # if mu is not 0, it should be used to regularize the least squares problem\n",
    "        # and \"force\" the background warp onto uncertain pixels\n",
    "        else:\n",
    "            # Calculate global parametrized warp\n",
    "            G_avg = np.mean(ATA, axis=(0, 1))\n",
    "            h_avg = np.mean(ATb, axis=(0, 1))\n",
    "            p_avg = np.linalg.solve(G_avg, h_avg)\n",
    "            d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "            # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "            if mu is None:\n",
    "                mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "            # Apply separable cross-correlation to calculate linear equation\n",
    "            G = scipy.ndimage.correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "            G = scipy.ndimage.correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            h = scipy.ndimage.correlate1d(\n",
    "                (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "            h = scipy.ndimage.correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "            # Refine estimate of displacement field\n",
    "            d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "\n",
    "    # TODO: return global displacement parameters and/or global displacement if mu != 0\n",
    "\n",
    "    return d\n",
    "\n",
    "flow_iterative(f1=img, f2=img, sigma=1.0, c1=c, c2=c, sigma_flow=1.0, num_iter=1, d=None, model=\"constant\", mu=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c33cc-7a73-4b46-a9cc-96922d1876a2",
   "metadata": {},
   "source": [
    "## 1D version (ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d525db9-c755-4c48-96d7-9afec88f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp_1d(signal, certainty, sigma): # probando\n",
    "    n = int(4 * sigma + 1)\n",
    "    x = np.arange(-n, n + 1, dtype=np.int32)\n",
    "    a = np.exp(-(x**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Calculate applicability kernel (1D)\n",
    "    ab = np.einsum(\"i,j->ij\", a, x)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, x)\n",
    "    \n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = certainty * signal\n",
    "    \n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty_like(abb)\n",
    "    v = np.empty_like(ab)\n",
    "    \n",
    "    # Apply separable cross-correlations\n",
    "    for i in range(ab.shape[-1]):\n",
    "        G[..., i] = scipy.ndimage.correlate1d(certainty, abb[..., i], mode=\"constant\", cval=0)\n",
    "        v[..., i] = scipy.ndimage.correlate1d(cf, ab[..., i], mode=\"constant\", cval=0)\n",
    "    \n",
    "    # Solve r for each pixel (eq. 4.8 of the thesis)\n",
    "    r = np.linalg.solve(G, v)\n",
    "    \n",
    "    # Quadratic term\n",
    "    A = np.empty((2, 2))\n",
    "    A[0, 0] = r[3]\n",
    "    A[0, 1] = r[5] / 2\n",
    "    A[1, 0] = A[0, 1]\n",
    "    A[1, 1] = r[4]\n",
    "    \n",
    "    # Linear term\n",
    "    B = np.empty(2)\n",
    "    B[0] = r[1]\n",
    "    B[1] = r[2]\n",
    "    \n",
    "    # Constant term\n",
    "    C = r[0]\n",
    "    \n",
    "    return A, B, C\n",
    "\n",
    "def flow_iterative_1d(signal1, signal2, sigma, c1, c2, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None):\n",
    "    # Calculate the polynomial expansion at each point in the signals\n",
    "    A1, B1, C1 = poly_exp_1d(signal1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp_1d(signal2, c2, sigma)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(2)\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel\n",
    "        d_ = d.astype(int)\n",
    "        \n",
    "        # Apply separable cross-correlation to calculate linear equation for each pixel\n",
    "        G = scipy.ndimage.correlate1d(A1 + A2, w, mode=\"constant\", cval=0)\n",
    "        h = scipy.ndimage.correlate1d(B2 - B1 + (A1 @ d_[..., None])[..., 0], w, mode=\"constant\", cval=0)\n",
    "\n",
    "        # Solve linear equation for each pixel\n",
    "        d = np.linalg.solve(G, h)\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Example usage:\n",
    "signal1 = np.array([1, 2, 3, 4, 5])\n",
    "signal2 = np.array([2, 3, 4, 5, 6])\n",
    "certainty1 = np.array([0.9, 0.8, 0.7, 0.6, 0.5])\n",
    "certainty2 = np.array([0.9, 0.8, 0.7, 0.6, 0.5])\n",
    "\n",
    "result = flow_iterative_1d(signal1, signal2, sigma=1.0, c1=certainty1, c2=certainty2, sigma_flow=1.0, num_iter=1, d=None, model=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3580f0-daa2-4779-8490-4522102ddcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
